### Starting TaskPrologue of job 594904 on f1083 at Wed May 17 22:05:42 CEST 2023
#   SLURM_JOB_NODELIST=f[1083-1084]
#   SLURM_JOB_NUM_NODES=2
#   SLURM_NTASKS=27
#   SLURM_NPROCS=27
#   SLURM_TASKS_PER_NODE=14,13
#   SLURM_JOB_CPUS_PER_NODE=72(x2)
#   SLURM_EXPORT_ENV=
Running on cores 0-71 with governor powersave
### Finished TaskPrologue
params: --nx=432 --ny=144 --nz=48 --npx=1 --npy=3 --npz=9
(f1083:0,1,2,3,4,5,6,7,8,9,10,11,12,13)
(f1084:14,15,16,17,18,19,20,21,22,23,24,25,26)

MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
MPI startup(): Warning: I_MPI_PMI_LIBRARY will be ignored since the hydra process manager was found
Abort(127) on node 14 (rank 14 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 127) - process 14
Abort(127) on node 16 (rank 16 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 127) - process 16
Abort(127) on node 24 (rank 24 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 127) - process 24
Abort(127) on node 25 (rank 25 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 127) - process 25
Abort(127) on node 17 (rank 17 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 127) - process 17
Abort(127) on node 18 (rank 18 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 127) - process 18
Abort(127) on node 19 (rank 19 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 127) - process 19
Abort(127) on node 20 (rank 20 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 127) - process 20
Abort(127) on node 21 (rank 21 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 127) - process 21
Abort(127) on node 22 (rank 22 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 127) - process 22
Abort(127) on node 23 (rank 23 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 127) - process 23
Abort(127) on node 26 (rank 26 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 127) - process 26
=== JOB_STATISTICS ===
=== current date     : Wed May 17 22:05:46 CEST 2023
= Job-ID             : 594904 on fritz
= Job-Name           : job_mpi.sh
= Job-Command        : /home/hpc/ihpc/ihpc061h/arm_code/optimized_version/HPCG_for_Arm/test_003_Convergence/test_1/job_mpi.sh
= Initial workdir    : /home/hpc/ihpc/ihpc061h/arm_code/optimized_version/HPCG_for_Arm/test_003_Convergence/test_1
= Queue/Partition    : multinode
= Slurm account      : ihpc with QOS=normal
= Features           : hwperf
= Requested resources: cpu=144,node=2,billing=144 for 00:30:00
= Elapsed runtime    : 00:00:04
= Total RAM usage    : 0.0 GiB 
= Node list          : f[1083-1084]
= Subm/Elig/Start/End: 2023-05-17T21:37:17 / 2023-05-17T21:37:17 / 2023-05-17T22:05:41 / 2023-05-17T22:05:45
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           23.3G    52.4G   104.9G        N/A  41,190      500K   1,000K        N/A    
    /home/woody          4.0K   500.0G   750.0G        N/A       1                           N/A    
    /home/vault          0.0K   524.3G  1048.6G        N/A       1      200K     400K        N/A    
    /lustre             12.0K     0.0K     0.0K        N/A       1   20,000      250K        N/A    
======================
