Fujitsu C/C++ Version 4.7.0   Wed Nov  2 18:23:55 2022
Compilation information
  Current directory : /lustre/home/gapinzon/arm_code/HPCG_for_Arm/ookami_fj
  Source file       : ../src/ComputeDotProduct.cpp
(line-no.)(optimize)
        1             /*
        2              *
        3              *  SPDX-License-Identifier: Apache-2.0
        4              *
        5              *  Copyright (C) 2019, Arm Limited and contributors
        6              *
        7              *  Licensed under the Apache License, Version 2.0 (the "License");
        8              *  you may not use this file except in compliance with the License.
        9              *  You may obtain a copy of the License at
       10              *
       11              *      http://www.apache.org/licenses/LICENSE-2.0
       12              *
       13              *  Unless required by applicable law or agreed to in writing, software
       14              *  distributed under the License is distributed on an "AS IS" BASIS,
       15              *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
       16              *  See the License for the specific language governing permissions and
       17              *  limitations under the License.
       18              *
       19              */
       20             
       21             //@HEADER
       22             // ***************************************************
       23             //
       24             // HPCG: High Performance Conjugate Gradient Benchmark
       25             //
       26             // Contact:
       27             // Michael A. Heroux ( maherou@sandia.gov)
       28             // Jack Dongarra     (dongarra@eecs.utk.edu)
       29             // Piotr Luszczek    (luszczek@eecs.utk.edu)
       30             //
       31             // ***************************************************
       32             //@HEADER
       33             
       34             /*!
       35              @file ComputeDotProduct.cpp
       36             
       37              HPCG routine
       38              */
       39             
       40             #ifndef HPCG_NO_MPI
       41             #include <mpi.h>
       42             #include "mytimer.hpp"
       43             #endif
       44             #ifndef HPCG_NO_OPENMP
       45             #include <omp.h>
       46             #endif
       47             
       48             #include "ComputeDotProduct.hpp"
       49             #include "ComputeDotProduct_ref.hpp"
       50             #include <cassert>
       51             #ifdef HPCG_USE_DDOT_ARMPL
       52             #include "armpl.h"
       53             #endif
       54             #ifdef HPCG_USE_SVE
       55             #include "arm_sve.h"
       56             #endif
       57             
       58             /*!
       59               Routine to compute the dot product of two vectors.
       60             
       61               This routine calls the reference dot-product implementation by default, but
       62               can be replaced by a custom routine that is optimized and better suited for
       63               the target system.
       64             
       65               @param[in]  n the number of vector elements (on this processor)
       66               @param[in]  x, y the input vectors
       67               @param[out] result a pointer to scalar value, on exit will contain the result.
       68               @param[out] time_allreduce the time it took to perform the communication between processes
       69               @param[out] isOptimized should be set to false if this routine uses the reference implementation (is not optimized); otherwise leave it unchanged
       70             
       71               @return returns 0 upon success and non-zero otherwise
       72             
       73               @see ComputeDotProduct_ref
       74             */
       75             #ifndef HPCG_MAN_OPT_DDOT_INTRINSICS
       76             int ComputeDotProduct(const local_int_t n, const Vector & x, const Vector & y,
       77                 double & result, double & time_allreduce, bool & isOptimized) {
       78             
       79             	assert(x.localLength >= n);
       80             	assert(y.localLength >= n);
       81             
       82             	double *xv = x.values;
       83             	double *yv = y.values;
       84             	double local_result = 0.0;
       85             
       86             #if defined HPCG_USE_SVE && !defined HPCG_MAN_OPT_DDOT
       87             	if ( xv == yv ) {
       88             #ifndef HPCG_NO_OPENMP
       89             #pragma omp parallel for reduction(+:local_result)
       90             #endif
       91             		for ( local_int_t i = 0; i < n; i += svcntd()) {
       92             			svbool_t pg = svwhilelt_b64(i, n);
       93             			svfloat64_t svx = svld1_f64(pg, &xv[i]);
       94             
       95                         svfloat64_t svlr = svmul_f64_z(pg, svx, svx);
       96             
       97                         local_result += svaddv_f64(svptrue_b64(), svlr);
       98             		}
       99             	} else {
      100             #ifndef HPCG_NO_OPENMP
      101             #pragma omp parallel for reduction(+:local_result)
      102             #endif
      103             		for ( local_int_t i = 0; i < n; i += svcntd()) {
      104             			svbool_t pg = svwhilelt_b64_u64(i, n);
      105             			svfloat64_t svx = svld1_f64(pg, &xv[i]);
      106             			svfloat64_t svy = svld1_f64(pg, &yv[i]);
      107             
      108                         svfloat64_t svlr = svmul_f64_z(pg, svx, svy);
      109                         
      110                         local_result += svaddv_f64(svptrue_b64(), svlr);
      111             		}
      112             	}
      113             #elif defined HPCG_USE_DDOT_ARMPL
      114             	local_result = cblas_ddot(n, xv, 1, yv, 1);
      115             #elif defined HPCG_MAN_OPT_DDOT
      116             	double local_result0 = 0.0, local_result1=0.0, local_result2=0.0, local_result3=0.0;
      117             /*	if (yv == xv) {
      118             #ifndef HPCG_NO_OPENMP
      119             #pragma omp parallel for reduction (+:local_result0,local_result1,local_result2,local_result3)
      120             #endif //HPCG_NO_OPENMP
      121             		for ( local_int_t i = 0; i < n; i+=4 ) {
      122                         local_result0 += xv[i+0] * xv[i+0];
      123                         local_result1 += xv[i+1] * xv[i+1];
      124                         local_result2 += xv[i+2] * xv[i+2];
      125                         local_result3 += xv[i+3] * xv[i+3];
      126                     }
      127             		local_result += local_result0+local_result1+local_result2+local_result3;
      128             	}
      129             	else {
      130             #ifndef HPCG_NO_OPENMP
      131             #pragma omp parallel for reduction (+:local_result0,local_result1,local_result2,local_result3)
      132             #endif //HPCG_NO_OPENMP
      133             		for ( local_int_t i = 0; i < n; i+=4 ) {
      134             			local_result0 += xv[i] * yv[i];
      135             			local_result1 += xv[i+1] * yv[i+1];
      136             			local_result2 += xv[i+2] * yv[i+2];
      137             			local_result3 += xv[i+3] * yv[i+3];
      138             		}
      139             		local_result += local_result0+local_result1+local_result2+local_result3;
      140             	}*/
      141             	if (yv == xv) {
      142             #ifndef HPCG_NO_OPENMP
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    SIMD(VL: AGNOSTIC; VL: 2 in 128-bit Interleave: 1)
                       <<< Loop-information End >>>
      143          m  #pragma omp parallel for reduction (+:local_result0,local_result1)
      144             #endif //HPCG_NO_OPENMP
      145             		for ( local_int_t i = 0; i < n; i+=2 ) {
      146                         local_result0 += xv[i+0] * xv[i+0];
      147                         local_result1 += xv[i+1] * xv[i+1];
      148                     }
      149             		local_result += local_result0+local_result1;
      150             	}
      151             	else {
      152             #ifndef HPCG_NO_OPENMP
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    SIMD(VL: AGNOSTIC; VL: 2 in 128-bit Interleave: 1)
                       <<< Loop-information End >>>
      153          m  #pragma omp parallel for reduction (+:local_result0,local_result1)
      154             #endif //HPCG_NO_OPENMP
      155             		for ( local_int_t i = 0; i < n; i+=2 ) {
      156             			local_result0 += xv[i] * yv[i];
      157             			local_result1 += xv[i+1] * yv[i+1];
      158             		}
      159             		local_result += local_result0+local_result1;
      160             	}
      161             	/*FIN*/
      162             #else //HPCG_USE_DDOT_ARMPL
      163             	if ( yv == xv ) {
      164             #ifndef HPCG_NO_OPENMP
      165             #pragma omp parallel for reduction (+:local_result)
      166             #endif //HPCG_NO_OPENMP
      167             		for ( local_int_t i = 0; i < n; i++ ) {
      168                         local_result += xv[i] * xv[i];
      169                     }
      170             	} else {
      171             #ifndef HPCG_NO_OPENMP
      172             #pragma omp parallel for reduction (+:local_result)
      173             #endif //HPCG_NO_OPENMP
      174             		for ( local_int_t i = 0; i < n; i++ ) {
      175             			local_result += xv[i] * yv[i];
      176             		}
      177             	}
      178             #endif //HPCG_USE_DDOT_ARMPL
      179             
      180             #ifndef HPCG_NO_MPI
      181             	// Use MPI's reduce function to collect all partial sums
      182             	double t0 = mytimer();
      183             	double global_result = 0.0;
      184             	MPI_Allreduce(&local_result, &global_result, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
      185             	result = global_result;
      186             	time_allreduce += mytimer() - t0;
      187             #else //HPCG_NO_MPI
      188             	time_allreduce += 0.0;
      189             	result = local_result;
      190             #endif //HPCG_NO_MPI
      191             
      192             	return 0;
      193             }
      194             #endif
      195             
      196             //2-way unrolling using intrinsics
      197             #ifdef HPCG_MAN_OPT_DDOT_INTRINSICS
      198             int ComputeDotProduct(const local_int_t n, const Vector & x, const Vector & y,
      199                 double & result, double & time_allreduce, bool & isOptimized) {
      200             
      201             	assert(x.localLength >= n);
      202             	assert(y.localLength >= n);
      203             
      204             	double *xv = x.values;
      205             	double *yv = y.values;
      206             	double local_result=0, local_result0 = 0.0, local_result1 = 0.0, local_result2=0, local_result3 =0;
      207             
      208             	if ( xv == yv ) {
      209             		uint64_t vz = svcntd();
      210             #ifndef HPCG_NO_OPENMP
      211             #pragma omp parallel for reduction(+:local_result0, local_result1, local_result2, local_result3)
      212             #endif
      213             		for ( local_int_t i = 0; i < n; i += 4*vz) {
      214             			svbool_t pg0 = svwhilelt_b64(i, n);
      215             			local_int_t ij=i+vz,i2j=i+2*vz,i3j=i+3*vz;
      216             			svbool_t pg1 = svwhilelt_b64(ij, n);
      217             			svbool_t pg2 = svwhilelt_b64(i2j, n);
      218             			svbool_t pg3 = svwhilelt_b64(i3j, n);
      219             			svfloat64_t svx0 = svld1_f64(pg0, &xv[i]);
      220             			svfloat64_t svx1 = svld1_f64(pg1, &xv[ij]);
      221             			svfloat64_t svx2 = svld1_f64(pg2, &xv[i2j]);
      222             			svfloat64_t svx3 = svld1_f64(pg3, &xv[i3j]);
      223             
      224                         svfloat64_t svlr0 = svmul_f64_z(pg0, svx0, svx0);
      225                         svfloat64_t svlr1 = svmul_f64_z(pg1, svx1, svx1);
      226                         svfloat64_t svlr2 = svmul_f64_z(pg2, svx2, svx2);
      227                         svfloat64_t svlr3 = svmul_f64_z(pg3, svx3, svx3);
      228             
      229                         local_result0 += svaddv_f64(svptrue_b64(), svlr0);
      230                         local_result1 += svaddv_f64(svptrue_b64(), svlr1);
      231                         local_result2 += svaddv_f64(svptrue_b64(), svlr2);
      232                         local_result3 += svaddv_f64(svptrue_b64(), svlr3);
      233             		}
      234             		local_result = local_result0+local_result1+local_result2+local_result3;
      235             	} else {
      236             #ifndef HPCG_NO_OPENMP
      237             #pragma omp parallel for reduction(+:local_result0, local_result1, local_result2, local_result3)
      238             #endif
      239             		for ( local_int_t i = 0; i < n; i += 4*svcntd()) {
      240             			svbool_t pg0 = svwhilelt_b64_u64(i, n);
      241             			svbool_t pg1 = svwhilelt_b64_u64(i+svcntd(), n);
      242             			svbool_t pg2 = svwhilelt_b64_u64(i+2*svcntd(), n);
      243             			svbool_t pg3 = svwhilelt_b64_u64(i+3*svcntd(), n);
      244             			svfloat64_t svx0 = svld1_f64(pg0, &xv[i]);
      245             			svfloat64_t svx1 = svld1_f64(pg1, &xv[i+svcntd()]);
      246             			svfloat64_t svx2 = svld1_f64(pg2, &xv[i+2*svcntd()]);
      247             			svfloat64_t svx3 = svld1_f64(pg3, &xv[i+3*svcntd()]);
      248             			svfloat64_t svy0 = svld1_f64(pg0, &yv[i]);
      249             			svfloat64_t svy1 = svld1_f64(pg1, &yv[i+svcntd()]);
      250             			svfloat64_t svy2 = svld1_f64(pg2, &yv[i+2*svcntd()]);
      251             			svfloat64_t svy3 = svld1_f64(pg3, &yv[i+3*svcntd()]);
      252             
      253                         svfloat64_t svlr0 = svmul_f64_z(pg0, svx0, svy0);
      254                         svfloat64_t svlr1 = svmul_f64_z(pg1, svx1, svy1);
      255                         svfloat64_t svlr2 = svmul_f64_z(pg2, svx2, svy2);
      256                         svfloat64_t svlr3 = svmul_f64_z(pg3, svx3, svy3);
      257                         
      258                         local_result0 += svaddv_f64(svptrue_b64(), svlr0);
      259                         local_result1 += svaddv_f64(svptrue_b64(), svlr1);
      260                         local_result2 += svaddv_f64(svptrue_b64(), svlr2);
      261                         local_result3 += svaddv_f64(svptrue_b64(), svlr3);
      262             		}
      263             		local_result = local_result0+local_result1+local_result2+local_result3;
      264             	}
      265             
      266             #ifndef HPCG_NO_MPI
      267             	// Use MPI's reduce function to collect all partial sums
      268             	double t0 = mytimer();
      269             	double global_result = 0.0;
      270             	MPI_Allreduce(&local_result, &global_result, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);
      271             	result = global_result;
      272             	time_allreduce += mytimer() - t0;
      273             #else //HPCG_NO_MPI
      274             	time_allreduce += 0.0;
      275             	result = local_result;
      276             #endif //HPCG_NO_MPI
      277             
      278             	return 0;
      279             }
      280             #endif //HPCG_MAN_OPT_DDOT_INTRINSICS
