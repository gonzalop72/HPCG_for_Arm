Fujitsu C/C++ Version 4.7.0   Tue Jul 18 15:54:39 2023
Compilation information
  Current directory : /lustre/home/gapinzon/arm_code/HPCG_for_Arm/ookami_fj2
  Source file       : ../src/ComputeSYMGS.cpp
(line-no.)(optimize)
        1             /*
        2              *
        3              *  SPDX-License-Identifier: Apache-2.0
        4              *
        5              *  Copyright (C) 2019, Arm Limited and contributors
        6              *
        7              *  Licensed under the Apache License, Version 2.0 (the "License");
        8              *  you may not use this file except in compliance with the License.
        9              *  You may obtain a copy of the License at
       10              *
       11              *      http://www.apache.org/licenses/LICENSE-2.0
       12              *
       13              *  Unless required by applicable law or agreed to in writing, software
       14              *  distributed under the License is distributed on an "AS IS" BASIS,
       15              *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
       16              *  See the License for the specific language governing permissions and
       17              *  limitations under the License.
       18              *
       19              */
       20             
       21             //@HEADER
       22             // ***************************************************
       23             //
       24             // HPCG: High Performance Conjugate Gradient Benchmark
       25             //
       26             // Contact:
       27             // Michael A. Heroux ( maherou@sandia.gov)
       28             // Jack Dongarra     (dongarra@eecs.utk.edu)
       29             // Piotr Luszczek    (luszczek@eecs.utk.edu)
       30             //
       31             // ***************************************************
       32             //@HEADER
       33             
       34             /*!
       35              @file ComputeSYMGS.cpp
       36             
       37              HPCG routine
       38              */
       39             
       40             #include "ComputeSYMGS.hpp"
       41             #include "ComputeSYMGS_ref.hpp"
       42             #ifndef HPCG_NO_MPI
       43             #include "ExchangeHalo.hpp"
       44             #endif
       45             
       46             #include "likwid_instrumentation.hpp"
       47             
       48             //#ifdef HPCG_MAN_OPT_SCH_SYMGS_ON
       49             	#define SCH_SYMGS(T)	schedule(runtime)
       50             //#else
       51             //	#define SCH_SYMGS(T)
       52             //#endif
       53             
       54             #ifndef HPCG_NO_OPENMP
       55             	#include "omp.h"
       56             #endif
       57             
       58             /**************************************************************************************************/
       59             /**************************************************************************************************/
       60             /**************************************************************************************************/
       61             /* SVE IMPLEMENTATIONS                                                                            */
       62             /**************************************************************************************************/
       63             /**************************************************************************************************/
       64             /**************************************************************************************************/
       65             
       66             #include "arm_sve.h"
       67             #ifdef HPCG_USE_SVE
       68             #include "arm_sve.h"
       69             
       70             #ifdef UNROLLING_4_A
       71             #elif defined(UNROLLING_4_B)
       72             	#define MANUAL_TASK_DISTRIBUTION
       73             #elif defined(UNROLLING_6_A)
       74             #elif defined(UNROLLING_6_B)
       75             #elif defined(UNROLLING_6_C)
       76             	#define MANUAL_TASK_DISTRIBUTION
       77             #elif defined(REF_UNROLLING_4)
       78             #else
       79             #endif
       80             
       81             
       82             inline void SYMGS_VERSION_1(const SparseMatrix& A, double * const& xv, const double * const& rv);	//UNROLL-2
       83             inline void SYMGS_VERSION_2(const SparseMatrix& A, double * const& xv, const double * const& rv);	//UNROLL-2 V2
       84             inline void SYMGS_VERSION_3(const SparseMatrix& A, double * const& xv, const double * const& rv);	//UNROLL-4 - OPTIMUM
       85             inline void SYMGS_VERSION_4(const SparseMatrix& A, double * const& xv, const double * const& rv);	//UNROLL-6
       86             #include "ComputeSYMGS_OPT.cpp"
       87             #include "ComputeSYMGS_OPT2.cpp" 
       88             
       89             /*
       90              * TDG VERSION
       91              */
       92             int ComputeSYMGS_TDG_SVE(const SparseMatrix & A, const Vector & r, Vector & x, TraceData &trace) {
       93             	assert(x.localLength == A.localNumberOfColumns);
       94             
       95             #ifndef HPCG_NO_MPI
       96             	ExchangeHalo(A, x);
       97             #endif
       98             
       99             	const double * const rv = r.values;
      100             	double * const xv = x.values;
      101             	double **matrixDiagonal = A.matrixDiagonal;
      102             
      103             LIKWID_START(trace.enabled, "symgs_tdg");
      104             
      105             #ifdef UNROLLING_4_A
      106             	SYMGS_VERSION_5(A, xv, rv); 
      107             #elif defined(UNROLLING_4_B)
      108             	SYMGS_VERSION_5(A, xv, rv); 
      109             #elif defined(UNROLLING_6_A)
      110             	SYMGS_VERSION_4(A, xv, rv); 
      111             #elif defined(UNROLLING_6_B)
      112             	SYMGS_VERSION_6(A, xv, rv); 
      113             #elif defined(UNROLLING_6_C)
      114             	SYMGS_VERSION_6(A, xv, rv); 
      115             #elif defined(REF_UNROLLING_4)
      116             	SYMGS_VERSION_3(A, xv, rv); 
      117             #else
      118             
      119             //#pragma statement scache_isolate_way L2=10
      120             //#pragma statement scache_isolate_assign xv
      121             	/*
      122             	 * FORWARD SWEEP
      123             	 */
      124             	for ( local_int_t l = 0; l < A.tdg.size(); l++ ) {
      125             
      126             		local_int_t totalSize = A.tdg[l].size();
      127             		local_int_t size1 = 2*(totalSize/2);
      128             		//#pragma loop nounroll
      129             		//#pragma loop nounroll_and_jam
      130             		//if((A.tdg[l].size()%2) == 0) {
      131             #ifndef HPCG_NO_OPENMP
      132             #pragma omp parallel
      133             {
      134             #pragma omp for nowait SCH_SYMGS(runtime)
      135             #endif
      136             		for ( local_int_t i = 0; i < size1; i+=2 ) {
      137             			local_int_t row_1 = A.tdg[l][i];
      138             			local_int_t row_2 = A.tdg[l][i+1];
      139             			const double * const currentValues_1 = A.matrixValues[row_1];
      140             			const local_int_t * const currentColIndices_1 = A.mtxIndL[row_1];
      141             			const int currentNumberOfNonzeros_1 = A.nonzerosInRow[row_1];
      142             			const double currentDiagonal_1 = matrixDiagonal[row_1][0];
      143             			svfloat64_t contribs_1 = svdup_f64(0.0);
      144             
      145             			const double * const currentValues_2 = A.matrixValues[row_2];
      146             			const local_int_t * const currentColIndices_2 = A.mtxIndL[row_2];
      147             			const int currentNumberOfNonzeros_2 = A.nonzerosInRow[row_2];
      148             			const double currentDiagonal_2 = matrixDiagonal[row_2][0];
      149             			svfloat64_t contribs_2 = svdup_f64(0.0);
      150             			
      151             			const int maxNumberOfNonzeros = std::max(currentNumberOfNonzeros_1, currentNumberOfNonzeros_2);
      152             
      153             			for ( local_int_t j = 0; j < maxNumberOfNonzeros; j += svcntd()) {
      154             				svbool_t pg_1 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_1);
      155             				
      156             				svfloat64_t mtxValues_1 = svld1_f64(pg_1, &currentValues_1[j]);
      157             				svuint64_t indices_1 = svld1sw_u64(pg_1, &currentColIndices_1[j]);
      158             				svfloat64_t xvv_1 = svld1_gather_u64index_f64(pg_1, xv, indices_1);
      159             
      160             				contribs_1 = svmla_f64_m(pg_1, contribs_1, xvv_1, mtxValues_1);
      161             
      162             				svbool_t pg_2 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_2);
      163             				svfloat64_t mtxValues_2 = svld1_f64(pg_2, &currentValues_2[j]);
      164             				svuint64_t indices_2 = svld1sw_u64(pg_2, &currentColIndices_2[j]);
      165             				svfloat64_t xvv_2 = svld1_gather_u64index_f64(pg_2, xv, indices_2);
      166             
      167             				contribs_2 = svmla_f64_m(pg_2, contribs_2, xvv_2, mtxValues_2);
      168             			}
      169             
      170             			double totalContribution_1 = svaddv_f64(svptrue_b64(), contribs_1);
      171             			double sum_1 = rv[row_1] - totalContribution_1;
      172             
      173             			sum_1 += xv[row_1] * currentDiagonal_1;
      174             			xv[row_1] = sum_1 / currentDiagonal_1;
      175             
      176             			double totalContribution_2 = svaddv_f64(svptrue_b64(), contribs_2);
      177             			double sum_2 = rv[row_2] - totalContribution_2;
      178             
      179             			sum_2 += xv[row_2] * currentDiagonal_2;
      180             			xv[row_2] = sum_2 / currentDiagonal_2;
      181             		}
      182             		//}
      183             		//else
      184             		//{
      185             #ifndef HPCG_NO_OPENMP
      186             //#pragma omp parallel for SCH_SYMGS(runtime)
      187             #pragma omp single 
      188             {
      189             #endif
      190             		if (size1 < totalSize) {
      191             			local_int_t i = size1;
      192             		//for ( local_int_t i = size1; i < totalSize; i++ ) {
      193             			local_int_t row = A.tdg[l][i];
      194             			const double * const currentValues = A.matrixValues[row];
      195             			const local_int_t * const currentColIndices = A.mtxIndL[row];
      196             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
      197             			const double currentDiagonal = matrixDiagonal[row][0];
      198             			svfloat64_t contribs = svdup_f64(0.0);
      199             
      200             			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
      201             				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
      202             				
      203             				svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
      204             				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
      205             				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
      206             
      207             				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
      208             			}
      209             
      210             			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
      211             			double sum = rv[row] - totalContribution;
      212             
      213             			sum += xv[row] * currentDiagonal;
      214             			xv[row] = sum / currentDiagonal;
      215             		//}
      216             		}
      217             #ifndef HPCG_NO_OPENMP
      218             }
      219             }
      220             #endif
      221             	}
      222             
      223             	/*
      224             	 * BACKWARD SWEEP
      225             	 */
      226             	for ( local_int_t l = A.tdg.size()-1; l >= 0; l-- ) {
      227             #ifndef HPCG_NO_OPENMP
      228             #pragma omp parallel for SCH_SYMGS(runtime)
      229             #endif
      230             		for ( local_int_t i = A.tdg[l].size()-1; i >= 0; i-- ) {
      231             			local_int_t row = A.tdg[l][i];
      232             			const double * const currentValues = A.matrixValues[row];
      233             			const local_int_t * const currentColIndices = A.mtxIndL[row];
      234             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
      235             			const double currentDiagonal = matrixDiagonal[row][0];
      236             			svfloat64_t contribs = svdup_f64(0.0);
      237             
      238             			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
      239             				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
      240             				
      241             				svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
      242             				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
      243             				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
      244             
      245             				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
      246             			}
      247             
      248             			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
      249             			double sum = rv[row] - totalContribution;
      250             
      251             			sum += xv[row] * currentDiagonal;
      252             			xv[row] = sum / currentDiagonal;
      253             		}
      254             
      255             /*#ifndef HPCG_NO_OPENMP
      256             #pragma omp parallel for SCH_SYMGS(runtime)
      257             #endif
      258             		for ( local_int_t i = size1-1; i >= 0; i-= 2 ) {
      259             			local_int_t row_1 = A.tdg[l][i];
      260             			local_int_t row_2 = A.tdg[l][i-1];
      261             			const double * const currentValues_1 = A.matrixValues[row_1];
      262             			const double * const currentValues_2 = A.matrixValues[row_2];
      263             			const local_int_t * const currentColIndices_1 = A.mtxIndL[row_1];
      264             			const local_int_t * const currentColIndices_2 = A.mtxIndL[row_2];
      265             			const int currentNumberOfNonzeros_1 = A.nonzerosInRow[row_1];
      266             			const int currentNumberOfNonzeros_2 = A.nonzerosInRow[row_2];
      267             			const double currentDiagonal_1 = matrixDiagonal[row_1][0];
      268             			const double currentDiagonal_2 = matrixDiagonal[row_2][0];
      269             			svfloat64_t contribs_1 = svdup_f64(0.0);
      270             			svfloat64_t contribs_2 = svdup_f64(0.0);
      271             
      272             			//#pragma loop nounroll
      273             			//#pragma loop nounroll_and_jam
      274             			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
      275             				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
      276             				
      277             				svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
      278             				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
      279             				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
      280             
      281             				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
      282             			}
      283             
      284             			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
      285             			double sum = rv[row] - totalContribution;
      286             
      287             			sum += xv[row] * currentDiagonal;
      288             			xv[row] = sum / currentDiagonal;
      289             		}*/
      290             	}
      291             //#pragma statement end_scache_isolate_assign
      292             //#pragma statement end_scache_isolate_way
      293             
      294             #endif //TEST_XX
      295             
      296             LIKWID_STOP(trace.enabled, "symgs_tdg");
      297             
      298             	return 0;
      299             }
      300             /*
      301              * END OF TDG VERSION
      302              */
      303             
      304             /*
      305              * TDG FUSED SYMGS-SPMV VERSION
      306              */
      307             int ComputeFusedSYMGS_SPMV_SVE(const SparseMatrix & A, const Vector & r, Vector & x, Vector & y, TraceData& trace) {
      308             	assert(x.localLength == A.localNumberOfColumns);
      309             
      310             #ifndef HPCG_NO_MPI
      311             	ExchangeHalo(A, x);
      312             #endif
      313             
      314             	const double * const rv = r.values;
      315             	double * const xv = x.values;
      316             	double **matrixDiagonal = A.matrixDiagonal;
      317             	double * const yv = y.values;
      318             
      319             	/*
      320             	 * FORWARD SWEEP
      321             	 */
      322    i        	for ( local_int_t l = 0; l < A.tdg.size(); l++ ) {
      323             #ifndef HPCG_NO_OPENMP
      324             #pragma omp parallel for SCH_SYMGS(runtime)
      325             #endif
      326   pi        		for ( local_int_t i = 0; i < A.tdg[l].size(); i++ ) {
      327   p         			local_int_t row = A.tdg[l][i];
      328   p         			const double * const currentValues = A.matrixValues[row];
      329   p         			const local_int_t * const currentColIndices = A.mtxIndL[row];
      330   p         			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
      331   p         			const double currentDiagonal = matrixDiagonal[row][0];
      332   p         			svfloat64_t contribs = svdup_f64(0.0);
      333             
      334   p      s  			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
      335   p      s  				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
      336             				
      337   p      s  				svfloat64_t mtxValues = svld1(pg, &currentValues[j]);
      338   p      s  				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
      339   p      s  				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
      340             
      341   p      s  				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
      342   p      s  			}
      343             
      344   p         			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
      345   p         			double sum = rv[row] - totalContribution;
      346             
      347   p         			sum += xv[row] * currentDiagonal;
      348   p         			xv[row] = sum / currentDiagonal;
      349   pi        		}
      350    i        	}
      351             
      352             	/*
      353             	 * BACKWARD SWEEP
      354             	 */
      355    i        	for ( local_int_t l = A.tdg.size()-1; l >= 0; l-- ) {
      356             #ifndef HPCG_NO_OPENMP
      357             #pragma omp parallel for SCH_SYMGS(runtime)
      358             #endif
      359   pi        		for ( local_int_t i = A.tdg[l].size(); i >= 0; i-- ) {
      360   p         			local_int_t row = A.tdg[l][i];
      361   p         			const double * const currentValues = A.matrixValues[row];
      362   p         			const local_int_t * const currentColIndices = A.mtxIndL[row];
      363   p         			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
      364   p         			const double currentDiagonal = matrixDiagonal[row][0];
      365   p         			svfloat64_t contribs = svdup_f64(0.0);
      366             
      367   p      s  			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
      368   p      s  				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
      369             				
      370   p      s  				svfloat64_t mtxValues = svld1(pg, &currentValues[j]);
      371   p      s  				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
      372   p      s  				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
      373             
      374   p      s  				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
      375   p      s  			}
      376             
      377   p         			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
      378   p         			totalContribution -= xv[row] * currentDiagonal; // remove diagonal contribution
      379   p         			double sum = rv[row] - totalContribution; // substract contributions from RHS
      380   p         			xv[row] = sum / currentDiagonal; // update row
      381             
      382             			// SPMV part
      383   p         			totalContribution += xv[row] * currentDiagonal; // add updated diagonal contribution
      384   p         			yv[row] = totalContribution; // update SPMV output vector
      385             			
      386   p         		}
      387             	}
      388             
      389             	return 0;
      390             }
      391             /*
      392              * END OF TDG FUSED SYMGS-SPMV VERSION
      393              */
      394             
      395             /*
      396              * BLOCK COLORED VERSION
      397              */
      398             int ComputeSYMGS_BLOCK_SVE(const SparseMatrix & A, const Vector & r, Vector & x, TraceData& trace ) {
      399             	assert(x.localLength >= A.localNumberOfColumns);
      400             
      401             #ifndef HPCG_NO_MPI
      402             	ExchangeHalo(A, x);
      403             #endif
      404             
      405             	double **matrixDiagonal = A.matrixDiagonal;
      406             	const double * const rv = r.values;
      407             	double * const xv = x.values;
      408             	local_int_t firstBlock = 0;
      409    i        	local_int_t lastBlock = firstBlock + A.numberOfBlocksInColor[0];
      410             
      411             LIKWID_START(trace.enabled, "symgs_bc");		
      412             
      413             	/*
      414             	 * FORWARD SWEEP
      415             	 */
      416             	for ( local_int_t color = 0; color < A.numberOfColors; color++ ) { // for each color
      417             		if ( color > 0 ) {
      418    i        			firstBlock += A.numberOfBlocksInColor[color-1];
      419    i        			lastBlock = firstBlock + A.numberOfBlocksInColor[color];
      420             		}
      421             #ifndef HPCG_NO_OPENMP
      422             #pragma omp parallel for SCH_SYMGS(runtime)
      423             #endif
      424   p         		for ( local_int_t block = firstBlock; block < lastBlock; block += A.chunkSize ) { // for each superblock with the same color
      425   p         			local_int_t firstRow = block * A.blockSize;
      426   p         			local_int_t firstChunk = firstRow / A.chunkSize;
      427   p         			local_int_t lastChunk = (firstRow + A.blockSize * A.chunkSize) / A.chunkSize;
      428             
      429   p         			for ( local_int_t chunk = firstChunk; chunk < lastChunk; chunk++ ) { // for each chunk of this super block
      430   p         				local_int_t first = A.chunkSize * chunk;
      431   p         				local_int_t last = first + A.chunkSize;
      432   p         				const int currentNumberOfNonzeros = A.nonzerosInChunk[chunk];
      433   p         				local_int_t i = first;
      434   p         				if ( A.chunkSize == 4 ) {
      435   p         					const double * const currentValues0 = A.matrixValues[i  ];
      436   p         					const double * const currentValues1 = A.matrixValues[i+1];
      437   p         					const double * const currentValues2 = A.matrixValues[i+2];
      438   p         					const double * const currentValues3 = A.matrixValues[i+3];
      439             
      440   p         					const local_int_t * const currentColIndices0 = A.mtxIndL[i  ];
      441   p         					const local_int_t * const currentColIndices1 = A.mtxIndL[i+1];
      442   p         					const local_int_t * const currentColIndices2 = A.mtxIndL[i+2];
      443   p         					const local_int_t * const currentColIndices3 = A.mtxIndL[i+3];
      444             
      445   p         					const double currentDiagonal0 = matrixDiagonal[i  ][0];
      446   p         					const double currentDiagonal1 = matrixDiagonal[i+1][0];
      447   p         					const double currentDiagonal2 = matrixDiagonal[i+2][0];
      448   p         					const double currentDiagonal3 = matrixDiagonal[i+3][0];
      449             
      450   p         					svfloat64_t contribs0 = svdup_f64(0.0);
      451   p         					svfloat64_t contribs1 = svdup_f64(0.0);
      452   p         					svfloat64_t contribs2 = svdup_f64(0.0);
      453   p         					svfloat64_t contribs3 = svdup_f64(0.0);
      454             
      455   p      s  					for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd() ) {
      456   p      s  						svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
      457             
      458   p      s  						svfloat64_t values0 = svld1_f64(pg, &currentValues0[j]);
      459   p      s  						svfloat64_t values1 = svld1_f64(pg, &currentValues1[j]);
      460   p      s  						svfloat64_t values2 = svld1_f64(pg, &currentValues2[j]);
      461   p      s  						svfloat64_t values3 = svld1_f64(pg, &currentValues3[j]);
      462             
      463   p      s  						svuint64_t indices0 = svld1sw_u64(pg, &currentColIndices0[j]);
      464   p      s  						svuint64_t indices1 = svld1sw_u64(pg, &currentColIndices1[j]);
      465   p      s  						svuint64_t indices2 = svld1sw_u64(pg, &currentColIndices2[j]);
      466   p      s  						svuint64_t indices3 = svld1sw_u64(pg, &currentColIndices3[j]);
      467             
      468   p      s  						svfloat64_t xvv0 = svld1_gather_u64index_f64(pg, xv, indices0);
      469   p      s  						svfloat64_t xvv1 = svld1_gather_u64index_f64(pg, xv, indices1);
      470   p      s  						svfloat64_t xvv2 = svld1_gather_u64index_f64(pg, xv, indices2);
      471   p      s  						svfloat64_t xvv3 = svld1_gather_u64index_f64(pg, xv, indices3);
      472             
      473   p      s  						contribs0 = svmla_f64_m(pg, contribs0, xvv0, values0);
      474   p      s  						contribs1 = svmla_f64_m(pg, contribs1, xvv1, values1);
      475   p      s  						contribs2 = svmla_f64_m(pg, contribs2, xvv2, values2);
      476   p      s  						contribs3 = svmla_f64_m(pg, contribs3, xvv3, values3);
      477   p      s  					}
      478             
      479   p         					double totalContribution0 = svaddv_f64(svptrue_b64(), contribs0);
      480   p         					double totalContribution1 = svaddv_f64(svptrue_b64(), contribs1);
      481   p         					double totalContribution2 = svaddv_f64(svptrue_b64(), contribs2);
      482   p         					double totalContribution3 = svaddv_f64(svptrue_b64(), contribs3);
      483             
      484   p         					double sum0 = rv[i  ] - totalContribution0;
      485   p         					double sum1 = rv[i+1] - totalContribution1;
      486   p         					double sum2 = rv[i+2] - totalContribution2;
      487   p         					double sum3 = rv[i+3] - totalContribution3;
      488             
      489   p         					sum0 += xv[i  ] * currentDiagonal0;
      490   p         					sum1 += xv[i+1] * currentDiagonal1;
      491   p         					sum2 += xv[i+2] * currentDiagonal2;
      492   p         					sum3 += xv[i+3] * currentDiagonal3;
      493             
      494   p         					xv[i  ] = sum0 / currentDiagonal0;
      495   p         					xv[i+1] = sum1 / currentDiagonal1;
      496   p         					xv[i+2] = sum2 / currentDiagonal2;
      497   p         					xv[i+3] = sum3 / currentDiagonal3;
      498   p         				} else if ( A.chunkSize == 2 ) {
      499   p         					const double * const currentValues0 = A.matrixValues[i  ];
      500   p         					const double * const currentValues1 = A.matrixValues[i+1];
      501             
      502   p         					const local_int_t * const currentColIndices0 = A.mtxIndL[i  ];
      503   p         					const local_int_t * const currentColIndices1 = A.mtxIndL[i+1];
      504             
      505   p         					const double currentDiagonal0 = matrixDiagonal[i  ][0];
      506   p         					const double currentDiagonal1 = matrixDiagonal[i+1][0];
      507             
      508   p         					svfloat64_t contribs0 = svdup_f64(0.0);
      509   p         					svfloat64_t contribs1 = svdup_f64(0.0);
      510             
      511   p      s  					for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd() ) {
      512   p      s  						svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
      513             
      514   p      s  						svfloat64_t values0 = svld1_f64(pg, &currentValues0[j]);
      515   p      s  						svfloat64_t values1 = svld1_f64(pg, &currentValues1[j]);
      516             
      517   p      s  						svuint64_t indices0 = svld1sw_u64(pg, &currentColIndices0[j]);
      518   p      s  						svuint64_t indices1 = svld1sw_u64(pg, &currentColIndices1[j]);
      519             
      520   p      s  						svfloat64_t xvv0 = svld1_gather_u64index_f64(pg, xv, indices0);
      521   p      s  						svfloat64_t xvv1 = svld1_gather_u64index_f64(pg, xv, indices1);
      522             
      523   p      s  						contribs0 = svmla_f64_m(pg, contribs0, xvv0, values0);
      524   p      s  						contribs1 = svmla_f64_m(pg, contribs1, xvv1, values1);
      525   p      s  					}
      526             
      527   p         					double totalContribution0 = svaddv_f64(svptrue_b64(), contribs0);
      528   p         					double totalContribution1 = svaddv_f64(svptrue_b64(), contribs1);
      529             
      530   p         					double sum0 = rv[i  ] - totalContribution0;
      531   p         					double sum1 = rv[i+1] - totalContribution1;
      532             
      533   p         					sum0 += xv[i  ] * currentDiagonal0;
      534   p         					sum1 += xv[i+1] * currentDiagonal1;
      535             
      536   p         					xv[i  ] = sum0 / currentDiagonal0;
      537   p         					xv[i+1] = sum1 / currentDiagonal1;
      538   p         				} else { //A.chunkSize == 1
      539   p         					const double * const currentValues0 = A.matrixValues[i  ];
      540             
      541   p         					const local_int_t * const currentColIndices0 = A.mtxIndL[i  ];
      542             
      543   p         					const double currentDiagonal0 = matrixDiagonal[i  ][0];
      544             
      545   p         					svfloat64_t contribs0 = svdup_f64(0.0);
      546             
      547   p      s  					for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd() ) {
      548   p      s  						svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
      549             
      550   p      s  						svfloat64_t values0 = svld1_f64(pg, &currentValues0[j]);
      551             
      552   p      s  						svuint64_t indices0 = svld1sw_u64(pg, &currentColIndices0[j]);
      553             
      554   p      s  						svfloat64_t xvv0 = svld1_gather_u64index_f64(pg, xv, indices0);
      555             
      556   p      s  						contribs0 = svmla_f64_m(pg, contribs0, xvv0, values0);
      557   p      s  					}
      558             
      559   p         					double totalContribution0 = svaddv_f64(svptrue_b64(), contribs0);
      560             
      561   p         					double sum0 = rv[i  ] - totalContribution0;
      562             
      563   p         					sum0 += xv[i  ] * currentDiagonal0;
      564             
      565   p         					xv[i  ] = sum0 / currentDiagonal0;
      566   p         				}
      567   p         			}
      568   p         		}
      569             	}
      570             
      571             	firstBlock = A.numberOfBlocks-1;
      572    i        	lastBlock = firstBlock - A.numberOfBlocksInColor[A.numberOfColors-1];
      573             	/*
      574             	 * BACKWARD SWEEP
      575             	 */
      576             	for ( local_int_t color = A.numberOfColors-1; color >= 0; color-- ) {
      577             		if ( color < A.numberOfColors-1 ) {
      578    i        			firstBlock -= A.numberOfBlocksInColor[color+1];
      579    i        			lastBlock = firstBlock - A.numberOfBlocksInColor[color];
      580             		}
      581             #ifndef HPCG_NO_OPENMP
      582             #pragma omp parallel for SCH_SYMGS(runtime)
      583             #endif
      584   p         		for ( local_int_t block = firstBlock; block > lastBlock; block -= A.chunkSize ) {
      585   p         			local_int_t firstRow = ((block+1) * A.blockSize) - 1;
      586   p         			local_int_t firstChunk = firstRow / A.chunkSize;
      587   p         			local_int_t lastChunk = (firstRow - A.blockSize * A.chunkSize) / A.chunkSize;
      588             
      589   p         			for ( local_int_t chunk = firstChunk; chunk > lastChunk; chunk-- ) {
      590   p         				local_int_t first = A.chunkSize * chunk;
      591   p         				local_int_t last = first + A.chunkSize;
      592             
      593   p         				const int currentNumberOfNonzeros = A.nonzerosInChunk[chunk];
      594   p         				local_int_t i = first;
      595   p         				if ( A.chunkSize == 4 ) {
      596   p         					const double * const currentValues3 = A.matrixValues[i+3];
      597   p         					const double * const currentValues2 = A.matrixValues[i+2];
      598   p         					const double * const currentValues1 = A.matrixValues[i+1];
      599   p         					const double * const currentValues0 = A.matrixValues[i  ];
      600             
      601   p         					const local_int_t * const currentColIndices3 = A.mtxIndL[i+3];
      602   p         					const local_int_t * const currentColIndices2 = A.mtxIndL[i+2];
      603   p         					const local_int_t * const currentColIndices1 = A.mtxIndL[i+1];
      604   p         					const local_int_t * const currentColIndices0 = A.mtxIndL[i  ];
      605             
      606   p         					const double currentDiagonal3 = matrixDiagonal[i+3][0];
      607   p         					const double currentDiagonal2 = matrixDiagonal[i+2][0];
      608   p         					const double currentDiagonal1 = matrixDiagonal[i+1][0];
      609   p         					const double currentDiagonal0 = matrixDiagonal[i  ][0];
      610             
      611   p         					svfloat64_t contribs3 = svdup_f64(0.0);
      612   p         					svfloat64_t contribs2 = svdup_f64(0.0);
      613   p         					svfloat64_t contribs1 = svdup_f64(0.0);
      614   p         					svfloat64_t contribs0 = svdup_f64(0.0);
      615             
      616   p      s  					for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd() ) {
      617   p      s  						svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
      618             
      619   p      s  						svfloat64_t values3 = svld1_f64(pg, &currentValues3[j]);
      620   p      s  						svfloat64_t values2 = svld1_f64(pg, &currentValues2[j]);
      621   p      s  						svfloat64_t values1 = svld1_f64(pg, &currentValues1[j]);
      622   p      s  						svfloat64_t values0 = svld1_f64(pg, &currentValues0[j]);
      623             
      624   p      s  						svuint64_t indices3 = svld1sw_u64(pg, &currentColIndices3[j]);
      625   p      s  						svuint64_t indices2 = svld1sw_u64(pg, &currentColIndices2[j]);
      626   p      s  						svuint64_t indices1 = svld1sw_u64(pg, &currentColIndices1[j]);
      627   p      s  						svuint64_t indices0 = svld1sw_u64(pg, &currentColIndices0[j]);
      628             
      629   p      s  						svfloat64_t xvv3 = svld1_gather_u64index_f64(pg, xv, indices3);
      630   p      s  						svfloat64_t xvv2 = svld1_gather_u64index_f64(pg, xv, indices2);
      631   p      s  						svfloat64_t xvv1 = svld1_gather_u64index_f64(pg, xv, indices1);
      632   p      s  						svfloat64_t xvv0 = svld1_gather_u64index_f64(pg, xv, indices0);
      633             
      634   p      s  						contribs3 = svmla_f64_m(pg, contribs3, xvv3, values3 );
      635   p      s  						contribs2 = svmla_f64_m(pg, contribs2, xvv2, values2 );
      636   p      s  						contribs1 = svmla_f64_m(pg, contribs1, xvv1, values1 );
      637   p      s  						contribs0 = svmla_f64_m(pg, contribs0, xvv0, values0 );
      638   p      s  					}
      639             
      640   p         					double totalContribution3 = svaddv_f64(svptrue_b64(), contribs3);
      641   p         					double totalContribution2 = svaddv_f64(svptrue_b64(), contribs2);
      642   p         					double totalContribution1 = svaddv_f64(svptrue_b64(), contribs1);
      643   p         					double totalContribution0 = svaddv_f64(svptrue_b64(), contribs0);
      644             
      645   p         					double sum3 = rv[i+3] - totalContribution3;
      646   p         					double sum2 = rv[i+2] - totalContribution2;
      647   p         					double sum1 = rv[i+1] - totalContribution1;
      648   p         					double sum0 = rv[i  ] - totalContribution0;
      649             
      650   p         					sum3 += xv[i+3] * currentDiagonal3;
      651   p         					sum2 += xv[i+2] * currentDiagonal2;
      652   p         					sum1 += xv[i+1] * currentDiagonal1;
      653   p         					sum0 += xv[i  ] * currentDiagonal0;
      654             					
      655   p         					xv[i+3] = sum3 / currentDiagonal3;
      656   p         					xv[i+2] = sum2 / currentDiagonal2;
      657   p         					xv[i+1] = sum1 / currentDiagonal1;
      658   p         					xv[i  ] = sum0 / currentDiagonal0;
      659   p         				} else if ( A.chunkSize == 2 ) {
      660   p         					const double * const currentValues1 = A.matrixValues[i+1];
      661   p         					const double * const currentValues0 = A.matrixValues[i  ];
      662             
      663   p         					const local_int_t * const currentColIndices1 = A.mtxIndL[i+1];
      664   p         					const local_int_t * const currentColIndices0 = A.mtxIndL[i  ];
      665             
      666   p         					const double currentDiagonal1 = matrixDiagonal[i+1][0];
      667   p         					const double currentDiagonal0 = matrixDiagonal[i  ][0];
      668             
      669   p         					svfloat64_t contribs1 = svdup_f64(0.0);
      670   p         					svfloat64_t contribs0 = svdup_f64(0.0);
      671             
      672   p      s  					for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd() ) {
      673   p      s  						svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
      674             
      675   p      s  						svfloat64_t values1 = svld1_f64(pg, &currentValues1[j]);
      676   p      s  						svfloat64_t values0 = svld1_f64(pg, &currentValues0[j]);
      677             
      678   p      s  						svuint64_t indices1 = svld1sw_u64(pg, &currentColIndices1[j]);
      679   p      s  						svuint64_t indices0 = svld1sw_u64(pg, &currentColIndices0[j]);
      680             
      681   p      s  						svfloat64_t xvv1 = svld1_gather_u64index_f64(pg, xv, indices1);
      682   p      s  						svfloat64_t xvv0 = svld1_gather_u64index_f64(pg, xv, indices0);
      683             
      684   p      s  						contribs1 = svmla_f64_m(pg, contribs1, xvv1, values1 );
      685   p      s  						contribs0 = svmla_f64_m(pg, contribs0, xvv0, values0 );
      686   p      s  					}
      687             
      688   p         					double totalContribution1 = svaddv_f64(svptrue_b64(), contribs1);
      689   p         					double totalContribution0 = svaddv_f64(svptrue_b64(), contribs0);
      690             
      691   p         					double sum1 = rv[i+1] - totalContribution1;
      692   p         					double sum0 = rv[i  ] - totalContribution0;
      693             
      694   p         					sum1 += xv[i+1] * currentDiagonal1;
      695   p         					sum0 += xv[i  ] * currentDiagonal0;
      696             					
      697   p         					xv[i+1] = sum1 / currentDiagonal1;
      698   p         					xv[i  ] = sum0 / currentDiagonal0;
      699   p         				} else { // A.chunkSize == 1
      700   p         					const double * const currentValues0 = A.matrixValues[i  ];
      701             
      702   p         					const local_int_t * const currentColIndices0 = A.mtxIndL[i  ];
      703             
      704   p         					const double currentDiagonal0 = matrixDiagonal[i  ][0];
      705             
      706   p         					svfloat64_t contribs0 = svdup_f64(0.0);
      707             
      708   p      s  					for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd() ) {
      709   p      s  						svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
      710             
      711   p      s  						svfloat64_t values0 = svld1_f64(pg, &currentValues0[j]);
      712             
      713   p      s  						svuint64_t indices0 = svld1sw_u64(pg, &currentColIndices0[j]);
      714             
      715   p      s  						svfloat64_t xvv0 = svld1_gather_u64index_f64(pg, xv, indices0);
      716             
      717   p      s  						contribs0 = svmla_f64_m(pg, contribs0, xvv0, values0 );
      718   p      s  					}
      719             
      720   p         					double totalContribution0 = svaddv_f64(svptrue_b64(), contribs0);
      721             
      722   p         					double sum0 = rv[i  ] - totalContribution0;
      723             
      724   p         					sum0 += xv[i  ] * currentDiagonal0;
      725             					
      726   p         				}
      727   p         			}
      728   p         		}
      729             	}
      730             LIKWID_STOP(trace.enabled, "symgs_bc");			
      731             
      732             	return 0;
      733             }
      734             /*
      735              * END OF BLOCK COLORED VERSION
      736              */
      737             #elif defined(HPCG_USE_NEON)
      738             
      739             /**************************************************************************************************/
      740             /**************************************************************************************************/
      741             /**************************************************************************************************/
      742             /* NEON IMPLEMENTATIONS                                                                           */
      743             /**************************************************************************************************/
      744             /**************************************************************************************************/
      745             /**************************************************************************************************/
      746             
      747             #include "arm_neon.h"
      748             
      749             /*
      750              * TDG VERSION
      751              */
      752             int ComputeSYMGS_TDG_NEON(const SparseMatrix & A, const Vector & r, Vector & x) {
      753             	assert(x.localLength == A.localNumberOfColumns);
      754             
      755             #ifndef HPCG_NO_MPI
      756             	ExchangeHalo(A, x);
      757             #endif
      758             
      759             	const double * const rv = r.values;
      760             	double * const xv = x.values;
      761             	double **matrixDiagonal = A.matrixDiagonal;
      762             
      763             	/*
      764             	 * FORWARD
      765             	 */
      766             	for ( local_int_t l = 0; l < A.tdg.size(); l++ ) {
      767             #ifndef HPCG_NO_OPENMP
      768             #pragma omp parallel for SCH_SYMGS(runtime)
      769             #endif
      770             		for ( local_int_t i = 0; i < A.tdg[l].size(); i++ ) {
      771             			local_int_t row = A.tdg[l][i];
      772             			const double * const currentValues = A.matrixValues[row];
      773             			const local_int_t * const currentColIndices = A.mtxIndL[row];
      774             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
      775             			const double currentDiagonal = matrixDiagonal[row][0];
      776             			float64x2_t contribs = vdupq_n_f64(0.0);
      777             
      778             			local_int_t j = 0;
      779             			for ( j = 0; j < currentNumberOfNonzeros-1; j+=2 ) {
      780             				// Load the needed j values
      781             				float64x2_t mtxValues = vld1q_f64(&currentValues[j]);
      782             				// Load the needed x values
      783             				double aux[] = { xv[currentColIndices[j]], xv[currentColIndices[j+1]] };
      784             				float64x2_t xvv = vld1q_f64(aux);
      785             				// Add the contribution
      786             				contribs = vfmaq_f64(contribs, mtxValues, xvv);
      787             			}
      788             			// reduce contributions
      789             			double totalContribution = vgetq_lane_f64(contribs, 0) + vgetq_lane_f64(contribs, 1);
      790             			double sum = rv[row] - totalContribution;
      791             			// Add missing values from last loop
      792             			if ( j < currentNumberOfNonzeros ) {
      793             				sum -= currentValues[j] * xv[currentColIndices[j]];
      794             			}
      795             			sum += xv[row] * currentDiagonal; // remove diagonal contribution
      796             			xv[row] = sum / currentDiagonal; // update row
      797             		}
      798             	}
      799             
      800             	/*
      801             	 * BACKWARD
      802             	 */
      803             	for ( local_int_t l = A.tdg.size()-1; l >= 0; l-- ) {
      804             #ifndef HPCG_NO_OPENMP
      805             #pragma omp parallel for SCH_SYMGS(runtime)
      806             #endif
      807             		for ( local_int_t i = A.tdg[l].size()-1; i >= 0; i-- ) {
      808             			local_int_t row = A.tdg[l][i];
      809             			const double * const currentValues = A.matrixValues[row];
      810             			const local_int_t * const currentColIndices = A.mtxIndL[row];
      811             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
      812             			const double currentDiagonal = matrixDiagonal[row][0];
      813             			float64x2_t contribs = vdupq_n_f64(0.0);
      814             
      815             			local_int_t j = 0;
      816             			for ( j = 0; j < currentNumberOfNonzeros-1; j+=2 ) {
      817             				// Load the needed j values
      818             				float64x2_t mtxValues = vld1q_f64(&currentValues[j]);
      819             				// Load the needed x values
      820             				double aux[] = { xv[currentColIndices[j]], xv[currentColIndices[j+1]] };
      821             				float64x2_t xvv = vld1q_f64(aux);
      822             				// Add the contribution
      823             				contribs = vfmaq_f64(contribs, mtxValues, xvv);
      824             			}
      825             			// reduce contributions
      826             			double totalContribution = vgetq_lane_f64(contribs, 0) + vgetq_lane_f64(contribs, 1);
      827             			double sum = rv[row] - totalContribution;
      828             			// Add missing values from last loop
      829             			if ( j < currentNumberOfNonzeros ) {
      830             				sum -= currentValues[j] * xv[currentColIndices[j]];
      831             			}
      832             			sum += xv[row] * currentDiagonal; // remove diagonal contribution
      833             			xv[row] = sum / currentDiagonal; // update row
      834             		}
      835             	}
      836             
      837             	return 0;
      838             }
      839             /*
      840              *
      841              */
      842             ////////////////////////////////////////////////////////////////////////////////
      843             ////////////////////////////////////////////////////////////////////////////////
      844             ////////////////////////////////////////////////////////////////////////////////
      845             /*
      846              * TDG FUSED VERSION
      847              */
      848             int ComputeFusedSYMGS_SPMV_NEON(const SparseMatrix & A, const Vector & r, Vector & x, Vector & y) {
      849             	assert(x.localLength == A.localNumberOfColumns);
      850             
      851             #ifndef HPCG_NO_MPI
      852             	ExchangeHalo(A, x);
      853             #endif
      854             
      855             	const double * const rv = r.values;
      856             	double * const xv = x.values;
      857             	double * const yv = y.values;
      858             	double **matrixDiagonal = A.matrixDiagonal;
      859             
      860             	/*
      861             	 * FORWARD
      862             	 */
      863             	for ( local_int_t l = 0; l < A.tdg.size(); l++ ) {
      864             #ifndef HPCG_NO_OPENMP
      865             #pragma omp parallel for SCH_SYMGS(runtime)
      866             #endif
      867             		for ( local_int_t i = 0; i < A.tdg[l].size(); i++ ) {
      868             			local_int_t row = A.tdg[l][i];
      869             			const double * const currentValues = A.matrixValues[row];
      870             			const local_int_t * const currentColIndices = A.mtxIndL[row];
      871             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
      872             			const double currentDiagonal = matrixDiagonal[row][0];
      873             			float64x2_t contribs = vdupq_n_f64(0.0);
      874             
      875             			local_int_t j = 0;
      876             			for ( j = 0; j < currentNumberOfNonzeros-1; j+=2 ) {
      877             				// Load the needed j values
      878             				float64x2_t mtxValues = vld1q_f64(&currentValues[j]);
      879             				// Load the needed x values
      880             				double aux[] = { xv[currentColIndices[j]], xv[currentColIndices[j+1]] };
      881             				float64x2_t xvv = vld1q_f64(aux);
      882             				// Add the contribution
      883             				contribs = vfmaq_f64(contribs, mtxValues, xvv);
      884             			}
      885             			// reduce contributions
      886             			double totalContribution = vgetq_lane_f64(contribs, 0) + vgetq_lane_f64(contribs, 1);
      887             			double sum = rv[row] - totalContribution;
      888             			// Add missing values from last loop
      889             			if ( j < currentNumberOfNonzeros ) {
      890             				sum -= currentValues[j] * xv[currentColIndices[j]];
      891             			}
      892             			sum += xv[row] * currentDiagonal; // remove diagonal contribution
      893             			xv[row] = sum / currentDiagonal; // update row
      894             		}
      895             	}
      896             
      897             	/*
      898             	 * BACKWARD (fusing SYMGS and SPMV)
      899             	 */
      900             	for ( local_int_t l = A.tdg.size()-1; l >= 0; l-- ) {
      901             #ifndef HPCG_NO_OPENMP
      902             #pragma omp parallel for SCH_SYMGS(runtime)
      903             #endif
      904             		for ( local_int_t i = A.tdg[l].size()-1; i >= 0; i-- ) {
      905             			local_int_t row = A.tdg[l][i];
      906             			const double * const currentValues = A.matrixValues[row];
      907             			const local_int_t * const currentColIndices = A.mtxIndL[row];
      908             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
      909             			const double currentDiagonal = matrixDiagonal[row][0];
      910             			float64x2_t contribs = vdupq_n_f64(0.0);
      911             
      912             			local_int_t j = 0;
      913             			for ( j = 0; j < currentNumberOfNonzeros-1; j+=2 ) {
      914             				// Load the needed j values
      915             				float64x2_t mtxValues = vld1q_f64(&currentValues[j]);
      916             				// Load the needed x values
      917             				double aux[] = { xv[currentColIndices[j]], xv[currentColIndices[j+1]] };
      918             				float64x2_t xvv = vld1q_f64(aux);
      919             				// Add the contribution
      920             				contribs = vfmaq_f64(contribs, mtxValues, xvv);
      921             			}
      922             			// reduce contributions
      923             			double totalContribution = vgetq_lane_f64(contribs, 0) + vgetq_lane_f64(contribs, 1);
      924             			// Add missing values from last loop
      925             			if ( j < currentNumberOfNonzeros ) {
      926             				totalContribution += currentValues[j] * xv[currentColIndices[j]];
      927             			}
      928             			totalContribution -= xv[row] * currentDiagonal; // remove diagonal contribution
      929             			double sum = rv[row] - totalContribution; // substract contributions from RHS
      930             			xv[row] = sum / currentDiagonal; // update row
      931             			// Fusion part
      932             			totalContribution += xv[row] * currentDiagonal; // add updated diagonal contribution
      933             			yv[row] = totalContribution; // update SPMV output vector
      934             		}
      935             	}
      936             
      937             	return 0;
      938             }
      939             /*
      940              *
      941              */
      942             ////////////////////////////////////////////////////////////////////////////////
      943             ////////////////////////////////////////////////////////////////////////////////
      944             ////////////////////////////////////////////////////////////////////////////////
      945             /*
      946              * BLOCK COLORED VERSION
      947              */
      948             int ComputeSYMGS_BLOCK_NEON(const SparseMatrix & A, const Vector & r, Vector & x) {
      949             
      950             	assert(x.localLength >= A.localNumberOfColumns);
      951             	
      952             #ifndef HPCG_NO_MPI
      953             	ExchangeHalo(A, x);
      954             #endif
      955             
      956             	double **matrixDiagonal = A.matrixDiagonal;
      957             	const double * const rv = r.values;
      958             	double * const xv = x.values;
      959             
      960             	local_int_t firstBlock = 0;
      961             	local_int_t lastBlock = firstBlock + A.numberOfBlocksInColor[0];
      962             	/*
      963             	 * FORWARD
      964             	 */
      965             	for ( local_int_t color = 0; color < A.numberOfColors; color++ ) { // for each color
      966             		if ( color > 0 ) {
      967             			firstBlock += A.numberOfBlocksInColor[color-1];
      968             			lastBlock = firstBlock + A.numberOfBlocksInColor[color];
      969             		}
      970             #ifndef HPCG_NO_OPENMP
      971             #pragma omp parallel for SCH_SYMGS(runtime)
      972             #endif
      973             		for ( local_int_t block = firstBlock; block < lastBlock; block += A.chunkSize ) { // for each super block with the same color
      974             			local_int_t firstRow = block * A.blockSize;
      975             			local_int_t firstChunk = firstRow / A.chunkSize;
      976             			local_int_t lastChunk = (firstRow + A.blockSize*A.chunkSize) / A.chunkSize;
      977             
      978             			for ( local_int_t chunk = firstChunk; chunk < lastChunk; chunk++ ) { // for each chunk of this super block
      979             				local_int_t first = A.chunkSize * chunk;
      980             				local_int_t last = first + A.chunkSize;
      981             
      982             				const int currentNumberOfNonzeros = A.nonzerosInChunk[chunk];
      983             				local_int_t i = first;
      984             				if ( A.chunkSize == 4 ) {
      985             					const double * const currentValues0 = A.matrixValues[i  ];
      986             					const double * const currentValues1 = A.matrixValues[i+1];
      987             					const double * const currentValues2 = A.matrixValues[i+2];
      988             					const double * const currentValues3 = A.matrixValues[i+3];
      989             
      990             					const local_int_t * const currentColIndices0 = A.mtxIndL[i  ];
      991             					const local_int_t * const currentColIndices1 = A.mtxIndL[i+1];
      992             					const local_int_t * const currentColIndices2 = A.mtxIndL[i+2];
      993             					const local_int_t * const currentColIndices3 = A.mtxIndL[i+3];
      994             
      995             					const double currentDiagonal[4] = { matrixDiagonal[i  ][0],\
      996             														matrixDiagonal[i+1][0],\
      997             														matrixDiagonal[i+2][0],\
      998             														matrixDiagonal[i+3][0]};
      999             					float64x2_t diagonal01 = vld1q_f64(&currentDiagonal[0]);
     1000             					float64x2_t diagonal23 = vld1q_f64(&currentDiagonal[2]);
     1001             
     1002             					float64x2_t contribs0 = vdupq_n_f64(0.0);
     1003             					float64x2_t contribs1 = vdupq_n_f64(0.0);
     1004             					float64x2_t contribs2 = vdupq_n_f64(0.0);
     1005             					float64x2_t contribs3 = vdupq_n_f64(0.0);
     1006             
     1007             					float64x2_t vrv01 = vld1q_f64(&rv[i]);
     1008             					float64x2_t vrv23 = vld1q_f64(&rv[i+2]);
     1009             
     1010             					float64x2_t vxv01 = vld1q_f64(&xv[i]);
     1011             					float64x2_t vxv23 = vld1q_f64(&xv[i+2]);
     1012             
     1013             					local_int_t j = 0;
     1014             					for ( j = 0; j < currentNumberOfNonzeros-1; j += 2 ) {
     1015             						// Load values
     1016             						float64x2_t values0 = vld1q_f64(&currentValues0[j]);
     1017             						float64x2_t values1 = vld1q_f64(&currentValues1[j]);
     1018             						float64x2_t values2 = vld1q_f64(&currentValues2[j]);
     1019             						float64x2_t values3 = vld1q_f64(&currentValues3[j]);
     1020             
     1021             						// Load x
     1022             						float64x2_t vxv0 = { xv[currentColIndices0[j]], xv[currentColIndices0[j+1]] };
     1023             						float64x2_t vxv1 = { xv[currentColIndices1[j]], xv[currentColIndices1[j+1]] };
     1024             						float64x2_t vxv2 = { xv[currentColIndices2[j]], xv[currentColIndices2[j+1]] };
     1025             						float64x2_t vxv3 = { xv[currentColIndices3[j]], xv[currentColIndices3[j+1]] };
     1026             
     1027             						// Add contribution
     1028             						contribs0 = vfmaq_f64(contribs0, values0, vxv0);
     1029             						contribs1 = vfmaq_f64(contribs1, values1, vxv1);
     1030             						contribs2 = vfmaq_f64(contribs2, values2, vxv2);
     1031             						contribs3 = vfmaq_f64(contribs3, values3, vxv3);
     1032             					}
     1033             					// Reduce contribution
     1034             					// First for i and i+1
     1035             					float64x2_t totalContribution01;
     1036             					totalContribution01 = vsetq_lane_f64(vaddvq_f64(contribs0), totalContribution01, 0);
     1037             					totalContribution01 = vsetq_lane_f64(vaddvq_f64(contribs1), totalContribution01, 1);
     1038             
     1039             					// Then for i+2 and i+3
     1040             					float64x2_t totalContribution23;
     1041             					totalContribution23 = vsetq_lane_f64(vaddvq_f64(contribs2), totalContribution23, 0);
     1042             					totalContribution23 = vsetq_lane_f64(vaddvq_f64(contribs3), totalContribution23, 1);
     1043             
     1044             					// Substract contributions from RHS
     1045             					float64x2_t sum01 = vsubq_f64(vrv01, totalContribution01);
     1046             					float64x2_t sum23 = vsubq_f64(vrv23, totalContribution23);
     1047             
     1048             					// Add contributions from missing elements (if any)
     1049             					if ( j < currentNumberOfNonzeros ) {
     1050             						// Load current values
     1051             						float64x2_t values01 = { currentValues0[j], currentValues1[j] };
     1052             						float64x2_t values23 = { currentValues2[j], currentValues3[j] };
     1053             
     1054             						// Load x
     1055             						float64x2_t vx01 = { xv[currentColIndices0[j]], xv[currentColIndices1[j]] };
     1056             						float64x2_t vx23 = { xv[currentColIndices2[j]], xv[currentColIndices3[j]] };
     1057             
     1058             						// Add contributions
     1059             						sum01 = vfmsq_f64(sum01, values01, vx01);
     1060             						sum23 = vfmsq_f64(sum23, values23, vx23);
     1061             					}
     1062             
     1063             					// Remove diagonal contribution and update rows i and i+1
     1064             					sum01 = vfmaq_f64(sum01, vxv01, diagonal01);
     1065             					xv[i  ] = vgetq_lane_f64(sum01, 0) / currentDiagonal[0];
     1066             					xv[i+1] = vgetq_lane_f64(sum01, 1) / currentDiagonal[1];
     1067             
     1068             					// Remove diagonal contribution and update rows i+2 and i+3
     1069             					sum23 = vfmaq_f64(sum23, vxv23, diagonal23);
     1070             					xv[i+2] = vgetq_lane_f64(sum23, 0) / currentDiagonal[2];
     1071             					xv[i+3] = vgetq_lane_f64(sum23, 1) / currentDiagonal[3];
     1072             				} else if ( A.chunkSize == 2 ) {
     1073             					const double * const currentValues0 = A.matrixValues[i  ];
     1074             					const double * const currentValues1 = A.matrixValues[i+1];
     1075             
     1076             					const local_int_t * const currentColIndices0 = A.mtxIndL[i  ];
     1077             					const local_int_t * const currentColIndices1 = A.mtxIndL[i+1];
     1078             
     1079             					const double currentDiagonal[2] = { matrixDiagonal[i  ][0],\
     1080             														matrixDiagonal[i+1][0]};
     1081             					float64x2_t diagonal01 = vld1q_f64(&currentDiagonal[0]);
     1082             
     1083             					float64x2_t contribs0 = vdupq_n_f64(0.0);
     1084             					float64x2_t contribs1 = vdupq_n_f64(0.0);
     1085             
     1086             					float64x2_t vrv01 = vld1q_f64(&rv[i]);
     1087             
     1088             					float64x2_t vxv01 = vld1q_f64(&xv[i]);
     1089             
     1090             					local_int_t j = 0;
     1091             					for ( j = 0; j < currentNumberOfNonzeros-1; j += 2 ) {
     1092             						// Load values
     1093             						float64x2_t values0 = vld1q_f64(&currentValues0[j]);
     1094             						float64x2_t values1 = vld1q_f64(&currentValues1[j]);
     1095             
     1096             						// Load x
     1097             						float64x2_t vxv0 = { xv[currentColIndices0[j]], xv[currentColIndices0[j+1]] };
     1098             						float64x2_t vxv1 = { xv[currentColIndices1[j]], xv[currentColIndices1[j+1]] };
     1099             
     1100             						// Add contribution
     1101             						contribs0 = vfmaq_f64(contribs0, values0, vxv0);
     1102             						contribs1 = vfmaq_f64(contribs1, values1, vxv1);
     1103             					}
     1104             					// Reduce contribution
     1105             					// First for i and i+1
     1106             					float64x2_t totalContribution01;
     1107             					totalContribution01 = vsetq_lane_f64(vaddvq_f64(contribs0), totalContribution01, 0);
     1108             					totalContribution01 = vsetq_lane_f64(vaddvq_f64(contribs1), totalContribution01, 1);
     1109             
     1110             					// Substract contributions from RHS
     1111             					float64x2_t sum01 = vsubq_f64(vrv01, totalContribution01);
     1112             
     1113             					// Add contributions from missing elements (if any)
     1114             					if ( j < currentNumberOfNonzeros ) {
     1115             						// Load current values
     1116             						float64x2_t values01 = { currentValues0[j], currentValues1[j] };
     1117             
     1118             						// Load x
     1119             						float64x2_t vx01 = { xv[currentColIndices0[j]], xv[currentColIndices1[j]] };
     1120             
     1121             						// Add contributions
     1122             						sum01 = vfmsq_f64(sum01, values01, vx01);
     1123             					}
     1124             
     1125             					// Remove diagonal contribution and update rows i and i+1
     1126             					sum01 = vfmaq_f64(sum01, vxv01, diagonal01);
     1127             					xv[i  ] = vgetq_lane_f64(sum01, 0) / currentDiagonal[0];
     1128             					xv[i+1] = vgetq_lane_f64(sum01, 1) / currentDiagonal[1];
     1129             				} else { // A.chunkSize == 1
     1130             					const double * const currentValues = A.matrixValues[i];
     1131             					const local_int_t * const currentColIndices = A.mtxIndL[i];
     1132             					const double currentDiagonal = matrixDiagonal[i][0];
     1133             					float64x2_t contribs = vdupq_n_f64(0.0);
     1134             
     1135             					local_int_t j = 0;
     1136             					for ( j = 0; j < currentNumberOfNonzeros-1; j += 2 ) {
     1137             						// Load values
     1138             						float64x2_t values = vld1q_f64(&currentValues[j]);
     1139             
     1140             						// Load x
     1141             						float64x2_t vxv = { xv[currentColIndices[j]], xv[currentColIndices[j+1]] };
     1142             
     1143             						// Add contribution
     1144             						contribs = vfmaq_f64(contribs, values, vxv);
     1145             					}
     1146             					// Reduce contribution
     1147             					// First for i and i+1
     1148             					double totalContribution;
     1149             					totalContribution = vaddvq_f64(contribs);
     1150             
     1151             					// Substract contributions from RHS
     1152             					double sum = rv[i] - totalContribution;
     1153             
     1154             					// Add contributions from missing elements (if any)
     1155             					if ( j < currentNumberOfNonzeros ) {
     1156             						sum -= currentValues[j] * xv[currentColIndices[j]];
     1157             					}
     1158             
     1159             					// Remove diagonal contribution and update rows i and i+1
     1160             					sum += xv[i] * currentDiagonal;
     1161             					xv[i] = sum / currentDiagonal;
     1162             				}
     1163             			}
     1164             		}
     1165             	}
     1166             
     1167             	firstBlock = A.numberOfBlocks-1;
     1168             	lastBlock = firstBlock - A.numberOfBlocksInColor[A.numberOfColors-1];
     1169             	/*
     1170             	 * BACKWARD
     1171             	 */
     1172             	for ( local_int_t color = A.numberOfColors-1; color >= 0; color-- ) {
     1173             		if ( color < A.numberOfColors-1 ) {
     1174             			firstBlock -= A.numberOfBlocksInColor[color+1];
     1175             			lastBlock = firstBlock - A.numberOfBlocksInColor[color];
     1176             		}
     1177             #ifndef HPCG_NO_OPENMP
     1178             #pragma omp parallel for SCH_SYMGS(runtime)
     1179             #endif
     1180             		for ( local_int_t block = firstBlock; block > lastBlock; block -= A.chunkSize ) { // we skip a whole superblock on each iteration
     1181             			local_int_t firstRow = ((block+1) * A.blockSize) - 1; // this is the last row of the last block (i.e., next block first row - 1)
     1182             			local_int_t firstChunk = firstRow / A.chunkSize; // this is the  chunk of the row above
     1183             			local_int_t lastChunk = (firstRow - A.blockSize*A.chunkSize) / A.chunkSize; 
     1184             
     1185             			for ( local_int_t chunk = firstChunk; chunk > lastChunk; chunk-- ) {
     1186             				local_int_t first = A.chunkSize * chunk;
     1187             				local_int_t last = first + A.chunkSize;
     1188             
     1189             				const int currentNumberOfNonzeros = A.nonzerosInChunk[chunk];
     1190             				if ( A.chunkSize == 4 ) {
     1191             					local_int_t i = last-1-3;
     1192             
     1193             					const double * const currentValues3 = A.matrixValues[i+3];
     1194             					const double * const currentValues2 = A.matrixValues[i+2];
     1195             					const double * const currentValues1 = A.matrixValues[i+1];
     1196             					const double * const currentValues0 = A.matrixValues[i  ];
     1197             
     1198             					const local_int_t * const currentColIndices3 = A.mtxIndL[i+3];
     1199             					const local_int_t * const currentColIndices2 = A.mtxIndL[i+2];
     1200             					const local_int_t * const currentColIndices1 = A.mtxIndL[i+1];
     1201             					const local_int_t * const currentColIndices0 = A.mtxIndL[i  ];
     1202             
     1203             					const double currentDiagonal[4] = {\
     1204             							matrixDiagonal[i  ][0],\
     1205             							matrixDiagonal[i+1][0],\
     1206             							matrixDiagonal[i+2][0],\
     1207             							matrixDiagonal[i+3][0]};
     1208             
     1209             					float64x2_t diagonal01 = vld1q_f64(&currentDiagonal[0]);
     1210             					float64x2_t diagonal23 = vld1q_f64(&currentDiagonal[2]);
     1211             
     1212             					float64x2_t contribs0 = vdupq_n_f64(0.0);
     1213             					float64x2_t contribs1 = vdupq_n_f64(0.0);
     1214             					float64x2_t contribs2 = vdupq_n_f64(0.0);
     1215             					float64x2_t contribs3 = vdupq_n_f64(0.0);
     1216             
     1217             					float64x2_t vrv23 = vld1q_f64(&rv[i+2]);
     1218             					float64x2_t vrv01 = vld1q_f64(&rv[i  ]);
     1219             
     1220             					float64x2_t vxv23 = vld1q_f64(&xv[i+2]);
     1221             					float64x2_t vxv01 = vld1q_f64(&xv[i  ]);
     1222             
     1223             					local_int_t j = 0;
     1224             					for ( j = currentNumberOfNonzeros-2; j >= 0; j -= 2 ) {
     1225             						// Load values
     1226             						float64x2_t values0 = vld1q_f64(&currentValues0[j]);
     1227             						float64x2_t values1 = vld1q_f64(&currentValues1[j]);
     1228             						float64x2_t values2 = vld1q_f64(&currentValues2[j]);
     1229             						float64x2_t values3 = vld1q_f64(&currentValues3[j]);
     1230             
     1231             						// Load x
     1232             						float64x2_t vxv0 = { xv[currentColIndices0[j]], xv[currentColIndices0[j+1]] };
     1233             						float64x2_t vxv1 = { xv[currentColIndices1[j]], xv[currentColIndices1[j+1]] };
     1234             						float64x2_t vxv2 = { xv[currentColIndices2[j]], xv[currentColIndices2[j+1]] };
     1235             						float64x2_t vxv3 = { xv[currentColIndices3[j]], xv[currentColIndices3[j+1]] };
     1236             
     1237             						// Add contribution
     1238             						contribs0 = vfmaq_f64(contribs0, values0, vxv0);
     1239             						contribs1 = vfmaq_f64(contribs1, values1, vxv1);
     1240             						contribs2 = vfmaq_f64(contribs2, values2, vxv2);
     1241             						contribs3 = vfmaq_f64(contribs3, values3, vxv3);
     1242             					}
     1243             					// Reduce contribution
     1244             					// First for i and i-1
     1245             					float64x2_t totalContribution01;
     1246             					totalContribution01 = vsetq_lane_f64(vaddvq_f64(contribs0), totalContribution01, 0);
     1247             					totalContribution01 = vsetq_lane_f64(vaddvq_f64(contribs1), totalContribution01, 1);
     1248             
     1249             					// Then for i-2 and i-3
     1250             					float64x2_t totalContribution23;
     1251             					totalContribution23 = vsetq_lane_f64(vaddvq_f64(contribs2), totalContribution23, 0);
     1252             					totalContribution23 = vsetq_lane_f64(vaddvq_f64(contribs3), totalContribution23, 1);
     1253             
     1254             					// Substract contributions from RHS
     1255             					float64x2_t sum23 = vsubq_f64(vrv23, totalContribution23);
     1256             					float64x2_t sum01 = vsubq_f64(vrv01, totalContribution01);
     1257             
     1258             					// Add contributions from missing elements (if any)
     1259             					if ( j == -1 ) {
     1260             						// Load current values
     1261             						float64x2_t values23 = { currentValues2[j+1], currentValues3[j+1] };
     1262             						float64x2_t values01 = { currentValues0[j+1], currentValues1[j+1] };
     1263             
     1264             						// Load x
     1265             						float64x2_t vx23 = { xv[currentColIndices2[j+1]], xv[currentColIndices3[j+1]] };
     1266             						float64x2_t vx01 = { xv[currentColIndices0[j+1]], xv[currentColIndices1[j+1]] };
     1267             
     1268             						// Add contributions
     1269             						sum23 = vfmsq_f64(sum23, values23, vx23);
     1270             						sum01 = vfmsq_f64(sum01, values01, vx01);
     1271             					}
     1272             
     1273             					// Remove diagonal contribution and update rows i-2 and i-3
     1274             					sum23 = vfmaq_f64(sum23, vxv23, diagonal23);
     1275             					xv[i+3] = vgetq_lane_f64(sum23, 1) / currentDiagonal[3];
     1276             					xv[i+2] = vgetq_lane_f64(sum23, 0) / currentDiagonal[2];
     1277             
     1278             					// Remove diagonal contribution and update rows i and i-1
     1279             					sum01 = vfmaq_f64(sum01, vxv01, diagonal01);
     1280             					xv[i+1] = vgetq_lane_f64(sum01, 1) / currentDiagonal[1];
     1281             					xv[i  ] = vgetq_lane_f64(sum01, 0) / currentDiagonal[0];
     1282             				} else if ( A.chunkSize == 2 ) {
     1283             					local_int_t i = last-1-1;
     1284             
     1285             					const double * const currentValues1 = A.matrixValues[i+1];
     1286             					const double * const currentValues0 = A.matrixValues[i  ];
     1287             
     1288             					const local_int_t * const currentColIndices1 = A.mtxIndL[i+1];
     1289             					const local_int_t * const currentColIndices0 = A.mtxIndL[i  ];
     1290             
     1291             					const double currentDiagonal[2] = {\
     1292             							matrixDiagonal[i  ][0],\
     1293             							matrixDiagonal[i+1][0]};
     1294             
     1295             					float64x2_t diagonal01 = vld1q_f64(&currentDiagonal[0]);
     1296             
     1297             					float64x2_t contribs0 = vdupq_n_f64(0.0);
     1298             					float64x2_t contribs1 = vdupq_n_f64(0.0);
     1299             
     1300             					float64x2_t vrv01 = vld1q_f64(&rv[i  ]);
     1301             
     1302             					float64x2_t vxv01 = vld1q_f64(&xv[i  ]);
     1303             
     1304             					local_int_t j = 0;
     1305             					for ( j = currentNumberOfNonzeros-2; j >= 0; j -= 2 ) {
     1306             						// Load values
     1307             						float64x2_t values0 = vld1q_f64(&currentValues0[j]);
     1308             						float64x2_t values1 = vld1q_f64(&currentValues1[j]);
     1309             
     1310             						// Load x
     1311             						float64x2_t vxv0 = { xv[currentColIndices0[j]], xv[currentColIndices0[j+1]] };
     1312             						float64x2_t vxv1 = { xv[currentColIndices1[j]], xv[currentColIndices1[j+1]] };
     1313             
     1314             						// Add contribution
     1315             						contribs0 = vfmaq_f64(contribs0, values0, vxv0);
     1316             						contribs1 = vfmaq_f64(contribs1, values1, vxv1);
     1317             					}
     1318             					// Reduce contribution
     1319             					// First for i and i-1
     1320             					float64x2_t totalContribution01;
     1321             					totalContribution01 = vsetq_lane_f64(vaddvq_f64(contribs0), totalContribution01, 0);
     1322             					totalContribution01 = vsetq_lane_f64(vaddvq_f64(contribs1), totalContribution01, 1);
     1323             
     1324             					// Substract contributions from RHS
     1325             					float64x2_t sum01 = vsubq_f64(vrv01, totalContribution01);
     1326             
     1327             					// Add contributions from missing elements (if any)
     1328             					if ( j == -1 ) {
     1329             						// Load current values
     1330             						float64x2_t values01 = { currentValues0[j+1], currentValues1[j+1] };
     1331             
     1332             						// Load x
     1333             						float64x2_t vx01 = { xv[currentColIndices0[j+1]], xv[currentColIndices1[j+1]] };
     1334             
     1335             						// Add contributions
     1336             						sum01 = vfmsq_f64(sum01, values01, vx01);
     1337             					}
     1338             
     1339             					// Remove diagonal contribution and update rows i and i-1
     1340             					sum01 = vfmaq_f64(sum01, vxv01, diagonal01);
     1341             					xv[i+1] = vgetq_lane_f64(sum01, 1) / currentDiagonal[1];
     1342             					xv[i  ] = vgetq_lane_f64(sum01, 0) / currentDiagonal[0];
     1343             				} else { // A.chunkSize == 1
     1344             					local_int_t i = last - 1; // == first
     1345             					const double * const currentValues = A.matrixValues[i];
     1346             					const local_int_t * const currentColIndices = A.mtxIndL[i];
     1347             					const double currentDiagonal = matrixDiagonal[i][0];
     1348             
     1349             					float64x2_t contribs = vdupq_n_f64(0.0);
     1350             
     1351             					local_int_t j = 0;
     1352             					for ( j = 0; j < currentNumberOfNonzeros-1; j += 2 ) {
     1353             						// Load values
     1354             						float64x2_t values = vld1q_f64(&currentValues[j]);
     1355             
     1356             						// Load x
     1357             						float64x2_t vxv = { xv[currentColIndices[j]], xv[currentColIndices[j+1]] };
     1358             
     1359             						// Add contribution
     1360             						contribs = vfmaq_f64(contribs, values, vxv);
     1361             					}
     1362             					// Reduce contribution
     1363             					double totalContribution = vaddvq_f64(contribs);
     1364             
     1365             					// Substract contribution from RHS
     1366             					double sum = rv[i] - totalContribution;
     1367             
     1368             					// Add contributions from missing elements (if any)
     1369             					if ( j < currentNumberOfNonzeros ) {
     1370             						sum -= currentValues[j] * xv[currentColIndices[j]];
     1371             					}
     1372             
     1373             					// Remove diagonal contribution and updated row i
     1374             					sum += xv[i] * currentDiagonal;
     1375             					xv[i] = sum / currentDiagonal;
     1376             				}
     1377             			}
     1378             		}
     1379             	}
     1380             
     1381             	return 0;
     1382             }
     1383             /*
     1384              *
     1385              */
     1386             #endif
     1387             //#else // !HPCG_USE_SVE ! HPCG_USE_NEON
     1388             
     1389             int ComputeFusedSYMGS_SPMV ( const SparseMatrix & A, const Vector & r, Vector & x, Vector & y ) {
     1390             	assert(x.localLength == A.localNumberOfColumns);
     1391             
     1392             #ifndef HPCG_NO_MPI
     1393             	ExchangeHalo(A, x);
     1394             #endif
     1395             
     1396             	const double * const rv = r.values;
     1397             	double * const xv = x.values;
     1398             	double * const yv = y.values;
     1399             	double **matrixDiagonal = A.matrixDiagonal;
     1400             
     1401             	/*
     1402             	 * FORWARD
     1403             	 */
     1404    i        	for ( local_int_t l = 0; l < A.tdg.size(); l++ ) {
     1405             #ifndef HPCG_NO_OPENMP
     1406             #pragma omp parallel for SCH_SYMGS(runtime)
     1407             #endif
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1408   pi        		for ( local_int_t i = 0; i < A.tdg[l].size(); i++ ) {
     1409   p         			local_int_t row = A.tdg[l][i];
     1410   p         			const double * const currentValues = A.matrixValues[row];
     1411   p         			const local_int_t * const currentColIndices = A.mtxIndL[row];
     1412   p         			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     1413   p         			const double currentDiagonal = matrixDiagonal[row][0];
     1414   p         			double sum = rv[row];
     1415             
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    SIMD(VL: 8)
                       <<<    SOFTWARE PIPELINING(IPC: 1.16, ITR: 192, MVE: 2, POL: S)
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1416   p     8v  			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j++ ) {
     1417   p     8v  				local_int_t curCol = currentColIndices[j];
     1418   p     8v  				sum -= currentValues[j] * xv[curCol];
     1419   p     8v  			}
     1420   p         			sum += xv[row] * currentDiagonal;
     1421   p         			xv[row] = sum / currentDiagonal;
     1422   pi        		}
     1423    i        	}
     1424             
     1425             	/*
     1426             	 * BACKWARD (fusing SYMGS and SPMV)
     1427             	 */
     1428    i        	for ( local_int_t l = A.tdg.size()-1; l >= 0; l-- ) {
     1429             #ifndef HPCG_NO_OPENMP
     1430             #pragma omp parallel for SCH_SYMGS(runtime)
     1431             #endif
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1432   pi        		for ( local_int_t i = A.tdg[l].size()-1; i >= 0; i-- ) {
     1433   p         			local_int_t row = A.tdg[l][i];
     1434   p         			const double * const currentValues = A.matrixValues[row];
     1435   p         			const local_int_t * const currentColIndices = A.mtxIndL[row];
     1436   p         			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     1437   p         			const double currentDiagonal = matrixDiagonal[row][0];
     1438   p         			double sum = 0.0;
     1439             
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    SIMD(VL: 8)
                       <<<    SOFTWARE PIPELINING(IPC: 1.16, ITR: 192, MVE: 2, POL: S)
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1440   p     8v  			for ( local_int_t j = currentNumberOfNonzeros-1; j >= 0; j-- ) {
     1441   p     8v  				local_int_t curCol = currentColIndices[j];
     1442   p     8v  				sum += currentValues[j] * xv[curCol];
     1443   p     8v  			}
     1444   p         			sum -= xv[row] * currentDiagonal;
     1445   p         			xv[row] = (rv[row] - sum) / currentDiagonal;
     1446   p         			sum += xv[row] * currentDiagonal;
     1447   p         			yv[row] = sum;
     1448   p         		}
     1449             	}
     1450             
     1451             	return 0;
     1452             }
     1453             
     1454             int ComputeSYMGS_TDG ( const SparseMatrix & A, const Vector & r, Vector & x, TraceData& trace ) {
     1455             
     1456             	assert( x.localLength == A.localNumberOfColumns);
     1457             
     1458             #ifndef HPCG_NO_MPI
     1459             	ExchangeHalo(A,x);
     1460             #endif
     1461             
     1462             	const double * const rv = r.values;
     1463             	double * const xv = x.values;
     1464             	double **matrixDiagonal = A.matrixDiagonal;
     1465             
     1466             /*#ifndef HPCG_NO_OPENMP
     1467             #pragma omp parallel SCH_SYMGS(runtime)
     1468             {
     1469             #endif
     1470             */
     1471             #pragma statement scache_isolate_way L2=10
     1472             #pragma statement scache_isolate_assign xv
     1473             
     1474             	/*
     1475             	 * FORWARD
     1476             	 */
     1477    i        	for ( local_int_t l = 0; l < A.tdg.size(); l++ ) {
     1478             #ifndef HPCG_NO_OPENMP
     1479             #pragma omp parallel for SCH_SYMGS(runtime)
     1480             #endif
     1481             		#pragma loop unroll_and_jam(4)
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1482   pi        		for ( local_int_t i = 0; i < A.tdg[l].size(); i++ ) {
     1483   p         			local_int_t row = A.tdg[l][i];
     1484   p         			const double * const currentValues = A.matrixValues[row];
     1485   p         			const local_int_t * const currentColIndices = A.mtxIndL[row];
     1486   p         			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     1487   p         			const double currentDiagonal = matrixDiagonal[row][0];
     1488   p         			double sum = rv[row];
     1489             
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    SIMD(VL: 8)
                       <<<    SOFTWARE PIPELINING(IPC: 1.16, ITR: 192, MVE: 2, POL: S)
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1490   p     8v  			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j++ ) {
     1491   p     8v  				local_int_t curCol = currentColIndices[j];
     1492   p     8v  				sum -= currentValues[j] * xv[curCol];
     1493   p     8v  			}
     1494   p         			sum += xv[row] * currentDiagonal;
     1495   p         			xv[row] = sum / currentDiagonal;
     1496   pi        		}
     1497    i        	}
     1498             
     1499             	/*
     1500             	 * BACKWARD
     1501             	 */
     1502    i        	for ( local_int_t l = A.tdg.size()-1; l >= 0; l-- ) {
     1503             #ifndef HPCG_NO_OPENMP
     1504             #pragma omp parallel for SCH_SYMGS(runtime)
     1505             #endif
     1506             		#pragma loop unroll_and_jam(4)
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1507   pi        		for ( local_int_t i = A.tdg[l].size()-1; i >= 0; i-- ) {
     1508   p         			local_int_t row = A.tdg[l][i];
     1509   p         			const double * const currentValues = A.matrixValues[row];
     1510   p         			const local_int_t * const currentColIndices = A.mtxIndL[row];
     1511   p         			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     1512   p         			const double currentDiagonal = matrixDiagonal[row][0];
     1513   p         			double sum = rv[row];
     1514             
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    SIMD(VL: 8)
                       <<<    SOFTWARE PIPELINING(IPC: 1.16, ITR: 192, MVE: 2, POL: S)
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1515   p     8v  			for ( local_int_t j = currentNumberOfNonzeros-1; j >= 0; j-- ) {
     1516   p     8v  				local_int_t curCol = currentColIndices[j];
     1517   p     8v  				sum -= currentValues[j] * xv[curCol];
     1518   p     8v  			}
     1519   p         			sum += xv[row] * currentDiagonal;
     1520   p         			xv[row] = sum / currentDiagonal;
     1521   p         		}
     1522             	}
     1523             
     1524             	#pragma statement end_scache_isolate_assign
     1525             	#pragma statement end_scache_isolate_way
     1526             /*#ifndef HPCG_NO_OPENMP
     1527             }
     1528             #endif*/
     1529             
     1530             	return 0;
     1531             }
     1532             
     1533             int ComputeSYMGS_BLOCK( const SparseMatrix & A, const Vector & r, Vector & x, TraceData& trace ) {
     1534             
     1535             	assert(x.localLength >= A.localNumberOfColumns);
     1536             	
     1537             #ifndef HPCG_NO_MPI
     1538             	ExchangeHalo(A, x);
     1539             #endif
     1540             
     1541             	const local_int_t nrow = A.localNumberOfRows;
     1542             	double **matrixDiagonal = A.matrixDiagonal;
     1543             	const double * const rv = r.values;
     1544             	double * const xv = x.values;
     1545             
     1546             	local_int_t firstBlock = 0;
     1547    i        	local_int_t lastBlock = firstBlock + A.numberOfBlocksInColor[0];
     1548             	/*
     1549             	 * FORWARD
     1550             	 */
     1551             	for ( local_int_t color = 0; color < A.numberOfColors; color++ ) {
     1552             		if ( color > 0 ) {
     1553    i        			firstBlock += A.numberOfBlocksInColor[color-1];
     1554    i        			lastBlock = firstBlock + A.numberOfBlocksInColor[color];
     1555             		}
     1556             #ifndef HPCG_NO_OPENMP
     1557             #pragma omp parallel for SCH_SYMGS(runtime)
     1558             #endif
     1559   p         		for ( local_int_t block = firstBlock; block < lastBlock; block += A.chunkSize ) {
     1560   p         			local_int_t firstRow = block * A.blockSize;
     1561   p         			local_int_t firstChunk = firstRow / A.chunkSize;
     1562   p         			local_int_t lastChunk = (firstRow + A.blockSize*A.chunkSize) / A.chunkSize;
     1563             
     1564   p         			for ( local_int_t chunk = firstChunk; chunk < lastChunk; chunk++ ) {
     1565   p         				local_int_t first = A.chunkSize * chunk;
     1566   p         				local_int_t last = first + A.chunkSize;
     1567             
     1568             				//for ( local_int_t i = first; i < last; i+= (A.chunkSize/2)) {
     1569   p         				local_int_t i = first;
     1570   p         				if ( A.chunkSize == 4 ) {
     1571   p         					double sum0 = rv[i+0];
     1572   p         					double sum1 = rv[i+1];
     1573   p         					double sum2 = rv[i+2];
     1574   p         					double sum3 = rv[i+3];
     1575             
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1576   pi     s  					for ( local_int_t j = 0; j < A.nonzerosInChunk[chunk]; j++ ) {
     1577   p      s  						sum0 -= A.matrixValues[i+0][j] * xv[A.mtxIndL[i+0][j]];
     1578   p      s  						sum1 -= A.matrixValues[i+1][j] * xv[A.mtxIndL[i+1][j]];
     1579   p      s  						sum2 -= A.matrixValues[i+2][j] * xv[A.mtxIndL[i+2][j]];
     1580   p      s  						sum3 -= A.matrixValues[i+3][j] * xv[A.mtxIndL[i+3][j]];
     1581   pi     s  					}
     1582   p         					sum0 += matrixDiagonal[i+0][0] * xv[i+0];
     1583   p         					xv[i+0] = sum0 / matrixDiagonal[i+0][0];
     1584   p         					sum1 += matrixDiagonal[i+1][0] * xv[i+1];
     1585   p         					xv[i+1] = sum1 / matrixDiagonal[i+1][0];
     1586   p         					sum2 += matrixDiagonal[i+2][0] * xv[i+2];
     1587   p         					xv[i+2] = sum2 / matrixDiagonal[i+2][0];
     1588   p         					sum3 += matrixDiagonal[i+3][0] * xv[i+3];
     1589   p         					xv[i+3] = sum3 / matrixDiagonal[i+3][0];
     1590   p         				} else if ( A.chunkSize == 2 ) {
     1591   p         					double sum0 = rv[i+0];
     1592   p         					double sum1 = rv[i+1];
     1593             
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1594   pi     s  					for ( local_int_t j = 0; j < A.nonzerosInChunk[chunk]; j++ ) {
     1595   p      s  						sum0 -= A.matrixValues[i+0][j] * xv[A.mtxIndL[i+0][j]];
     1596   p      s  						sum1 -= A.matrixValues[i+1][j] * xv[A.mtxIndL[i+1][j]];
     1597   pi     s  					}
     1598   p         					sum0 += matrixDiagonal[i+0][0] * xv[i+0];
     1599   p         					xv[i+0] = sum0 / matrixDiagonal[i+0][0];
     1600   p         					sum1 += matrixDiagonal[i+1][0] * xv[i+1];
     1601   p         					xv[i+1] = sum1 / matrixDiagonal[i+1][0];
     1602   p         				} else { // A.chunkSize == 1
     1603   p         					double sum0 = rv[i+0];
     1604             
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1605   pi     s  					for ( local_int_t j = 0; j < A.nonzerosInChunk[chunk]; j++ ) {
     1606   p      s  						sum0 -= A.matrixValues[i+0][j] * xv[A.mtxIndL[i+0][j]];
     1607   pi     s  					}
     1608   p         					sum0 += matrixDiagonal[i+0][0] * xv[i+0];
     1609   p         					xv[i+0] = sum0 / matrixDiagonal[i+0][0];
     1610   p         				}
     1611   p         			}
     1612   p         		}
     1613             	}
     1614             
     1615             	firstBlock = A.numberOfBlocks-1;
     1616    i        	lastBlock = firstBlock - A.numberOfBlocksInColor[A.numberOfColors-1];
     1617             	/*
     1618             	 * BACKWARD
     1619             	 */
     1620             	for ( local_int_t color = A.numberOfColors-1; color >= 0; color-- ) {
     1621             		if ( color < A.numberOfColors-1 ) {
     1622    i        			firstBlock -= A.numberOfBlocksInColor[color+1];
     1623    i        			lastBlock = firstBlock - A.numberOfBlocksInColor[color];
     1624             		}
     1625             #ifndef HPCG_NO_OPENMP
     1626             #pragma omp parallel for SCH_SYMGS(runtime)
     1627             #endif
     1628   p         		for ( local_int_t block = firstBlock; block > lastBlock; block -= A.chunkSize ) {
     1629   p         			local_int_t firstRow = ((block+1) * A.blockSize) - 1; // this is the last row of the last block
     1630   p         			local_int_t firstChunk = firstRow / A.chunkSize; // this is the  chunk of the row above
     1631   p         			local_int_t lastChunk = (firstRow - A.blockSize*A.chunkSize) / A.chunkSize; 
     1632             
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1633   p         			for ( local_int_t chunk = firstChunk; chunk > lastChunk; chunk-- ) {
     1634   p         				local_int_t first = A.chunkSize * chunk;
     1635   p         				local_int_t last = first + A.chunkSize;
     1636             
     1637             				//for ( local_int_t i = last-1; i >= first; i -= (A.chunkSize/2)) {
     1638   p         				local_int_t i = last-1;
     1639   p         				if ( A.chunkSize == 4 ) {
     1640   p         					double sum3 = rv[i-3];
     1641   p         					double sum2 = rv[i-2];
     1642   p         					double sum1 = rv[i-1];
     1643   p         					double sum0 = rv[i  ];
     1644             
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    SIMD(VL: 8)
                       <<<    SOFTWARE PIPELINING(IPC: 1.28, ITR: 32, MVE: 2, POL: S)
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1645   pi     v  					for ( local_int_t j = A.nonzerosInChunk[chunk]-1; j >= 0; j-- ) {
     1646   p      v  						sum3 -= A.matrixValues[i-3][j] * xv[A.mtxIndL[i-3][j]];
     1647   p      v  						sum2 -= A.matrixValues[i-2][j] * xv[A.mtxIndL[i-2][j]];
     1648   p      v  						sum1 -= A.matrixValues[i-1][j] * xv[A.mtxIndL[i-1][j]];
     1649   p      v  						sum0 -= A.matrixValues[i  ][j] * xv[A.mtxIndL[i  ][j]];
     1650   p      v  					}
     1651   p         					sum3 += matrixDiagonal[i-3][0] * xv[i-3];
     1652   p         					xv[i-3] = sum3 / matrixDiagonal[i-3][0];
     1653             
     1654   p         					sum2 += matrixDiagonal[i-2][0] * xv[i-2];
     1655   p         					xv[i-2] = sum2 / matrixDiagonal[i-2][0];
     1656             
     1657   p         					sum1 += matrixDiagonal[i-1][0] * xv[i-1];
     1658   p         					xv[i-1] = sum1 / matrixDiagonal[i-1][0];
     1659             
     1660   p         					sum0 += matrixDiagonal[i  ][0] * xv[i  ];
     1661   p         					xv[i  ] = sum0 / matrixDiagonal[i  ][0];
     1662   p         				} else if ( A.chunkSize == 2 ) {
     1663   p         					double sum1 = rv[i-1];
     1664   p         					double sum0 = rv[i  ];
     1665             
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    SIMD(VL: 8)
                       <<<    SOFTWARE PIPELINING(IPC: 1.16, ITR: 96, MVE: 2, POL: S)
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1666   pi    4v  					for ( local_int_t j = A.nonzerosInChunk[chunk]-1; j >= 0; j-- ) {
     1667   p     4v  						sum1 -= A.matrixValues[i-1][j] * xv[A.mtxIndL[i-1][j]];
     1668   p     4v  						sum0 -= A.matrixValues[i  ][j] * xv[A.mtxIndL[i  ][j]];
     1669   p     4v  					}
     1670             
     1671   p         					sum1 += matrixDiagonal[i-1][0] * xv[i-1];
     1672   p         					xv[i-1] = sum1 / matrixDiagonal[i-1][0];
     1673             
     1674   p         					sum0 += matrixDiagonal[i  ][0] * xv[i  ];
     1675   p         					xv[i  ] = sum0 / matrixDiagonal[i  ][0];
     1676   p         				} else { // A.chunkSize == 1
     1677   p         					double sum0 = rv[i  ];
     1678             
                       <<< Loop-information Start >>>
                       <<<  [OPTIMIZATION]
                       <<<    SIMD(VL: 8)
                       <<<    SOFTWARE PIPELINING(IPC: 1.16, ITR: 192, MVE: 2, POL: S)
                       <<<    PREFETCH(HARD) Expected by compiler :
                       <<<      (unknown)
                       <<< Loop-information  End >>>
     1679   pi    8v  					for ( local_int_t j = A.nonzerosInChunk[chunk]-1; j >= 0; j-- ) {
     1680   p     8v  						sum0 -= A.matrixValues[i  ][j] * xv[A.mtxIndL[i  ][j]];
     1681   p     8v  					}
     1682             
     1683   p         					sum0 += matrixDiagonal[i  ][0] * xv[i  ];
     1684   p         					xv[i  ] = sum0 / matrixDiagonal[i  ][0];
     1685   p         				}
     1686   p         			}
     1687   p         		}
     1688             	}
     1689             
     1690             	return 0;
     1691             }
     1692             //#endif
     1693             
     1694             
     1695             
     1696             /*!
     1697               Routine to compute one step of symmetric Gauss-Seidel:
     1698             
     1699               Assumption about the structure of matrix A:
     1700               - Each row 'i' of the matrix has nonzero diagonal value whose address is matrixDiagonal[i]
     1701               - Entries in row 'i' are ordered such that:
     1702                    - lower triangular terms are stored before the diagonal element.
     1703                    - upper triangular terms are stored after the diagonal element.
     1704                    - No other assumptions are made about entry ordering.
     1705             
     1706               Symmetric Gauss-Seidel notes:
     1707               - We use the input vector x as the RHS and start with an initial guess for y of all zeros.
     1708               - We perform one forward sweep.  Since y is initially zero we can ignore the upper triangular terms of A.
     1709               - We then perform one back sweep.
     1710                    - For simplicity we include the diagonal contribution in the for-j loop, then correct the sum after
     1711             
     1712               @param[in] A the known system matrix
     1713               @param[in] r the input vector
     1714               @param[inout] x On entry, x should contain relevant values, on exit x contains the result of one symmetric GS sweep with r as the RHS.
     1715             
     1716               @return returns 0 upon success and non-zero otherwise
     1717             
     1718               @warning Early versions of this kernel (Version 1.1 and earlier) had the r and x arguments in reverse order, and out of sync with other kernels.
     1719             
     1720               @see ComputeSYMGS_ref
     1721             */
     1722             int ComputeSYMGS( const SparseMatrix & A, const Vector & r, Vector & x, TraceData& trace) {
     1723             
     1724             	// This function is just a stub right now which decides which implementation of the SYMGS will be executed (TDG or block coloring)
     1725             	if ( A.TDG ) {
     1726             #ifdef HPCG_USE_NEON
     1727             		return ComputeSYMGS_TDG_NEON(A, r, x);
     1728             #elif defined HPCG_USE_SVE
     1729    i        		return ComputeSYMGS_TDG_SVE(A, r, x, trace);
     1730             #else
     1731             		return ComputeSYMGS_TDG(A, r, x, trace);
     1732             #endif
     1733             	}
     1734             #ifdef HPCG_USE_NEON
     1735             	return ComputeSYMGS_BLOCK_NEON(A, r, x);
     1736             #elif defined HPCG_USE_SVE
     1737             	return ComputeSYMGS_BLOCK_SVE(A, r, x, trace);
     1738             #else
     1739             	return ComputeSYMGS_BLOCK(A, r, x, trace);
     1740             #endif
     1741             }
     1742             
     1743             inline void SYMGS_VERSION_1(const SparseMatrix& A, double * const& xv, const double * const& rv) {
     1744             	
     1745             	double **matrixDiagonal = A.matrixDiagonal;
     1746             
     1747             	/*
     1748             	 * FORWARD SWEEP
     1749             	 */
     1750             	for ( local_int_t l = 0; l < A.tdg.size(); l++ ) {
     1751             		local_int_t tdgLevelSize = A.tdg[l].size();
     1752             		if((tdgLevelSize%2) == 0) {
     1753             #ifndef HPCG_NO_OPENMP
     1754             #pragma omp parallel for SCH_SYMGS(runtime)
     1755             #endif
     1756             		for ( local_int_t i = 0; i < tdgLevelSize; i+=2 ) {
     1757             			local_int_t row_1 = A.tdg[l][i];
     1758             			local_int_t row_2 = A.tdg[l][i+1];
     1759             			const double * const currentValues_1 = A.matrixValues[row_1];
     1760             			const local_int_t * const currentColIndices_1 = A.mtxIndL[row_1];
     1761             			const int currentNumberOfNonzeros_1 = A.nonzerosInRow[row_1];
     1762             			const double currentDiagonal_1 = matrixDiagonal[row_1][0];
     1763             			svfloat64_t contribs_1 = svdup_f64(0.0);
     1764             
     1765             			const double * const currentValues_2 = A.matrixValues[row_2];
     1766             			const local_int_t * const currentColIndices_2 = A.mtxIndL[row_2];
     1767             			const int currentNumberOfNonzeros_2 = A.nonzerosInRow[row_2];
     1768             			const double currentDiagonal_2 = matrixDiagonal[row_2][0];
     1769             			svfloat64_t contribs_2 = svdup_f64(0.0);
     1770             			
     1771             			const int maxNumberOfNonzeros = std::max(currentNumberOfNonzeros_1, currentNumberOfNonzeros_2);
     1772             
     1773             			for ( local_int_t j = 0; j < maxNumberOfNonzeros; j += svcntd()) {
     1774             				svbool_t pg_1 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_1);
     1775             				
     1776             				svfloat64_t mtxValues_1 = svld1_f64(pg_1, &currentValues_1[j]);
     1777             				svuint64_t indices_1 = svld1sw_u64(pg_1, &currentColIndices_1[j]);
     1778             				svfloat64_t xvv_1 = svld1_gather_u64index_f64(pg_1, xv, indices_1);
     1779             
     1780             				contribs_1 = svmla_f64_m(pg_1, contribs_1, xvv_1, mtxValues_1);
     1781             
     1782             				svbool_t pg_2 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_2);
     1783             				svfloat64_t mtxValues_2 = svld1_f64(pg_2, &currentValues_2[j]);
     1784             				svuint64_t indices_2 = svld1sw_u64(pg_2, &currentColIndices_2[j]);
     1785             				svfloat64_t xvv_2 = svld1_gather_u64index_f64(pg_2, xv, indices_2);
     1786             
     1787             				contribs_2 = svmla_f64_m(pg_2, contribs_2, xvv_2, mtxValues_2);
     1788             			}
     1789             
     1790             			double totalContribution_1 = svaddv_f64(svptrue_b64(), contribs_1);
     1791             			double sum_1 = rv[row_1] - totalContribution_1;
     1792             
     1793             			sum_1 += xv[row_1] * currentDiagonal_1;
     1794             			xv[row_1] = sum_1 / currentDiagonal_1;
     1795             
     1796             			double totalContribution_2 = svaddv_f64(svptrue_b64(), contribs_2);
     1797             			double sum_2 = rv[row_2] - totalContribution_2;
     1798             
     1799             			sum_2 += xv[row_2] * currentDiagonal_2;
     1800             			xv[row_2] = sum_2 / currentDiagonal_2;
     1801             		}
     1802             		}
     1803             		else
     1804             		{
     1805             #ifndef HPCG_NO_OPENMP
     1806             #pragma omp parallel for SCH_SYMGS(runtime)
     1807             #endif
     1808             		for ( local_int_t i = 0; i < tdgLevelSize; i++ ) {
     1809             			local_int_t row = A.tdg[l][i];
     1810             			const double * const currentValues = A.matrixValues[row];
     1811             			const local_int_t * const currentColIndices = A.mtxIndL[row];
     1812             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     1813             			const double currentDiagonal = matrixDiagonal[row][0];
     1814             			svfloat64_t contribs = svdup_f64(0.0);
     1815             
     1816             			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
     1817             				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
     1818             				
     1819             				svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
     1820             				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
     1821             				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
     1822             
     1823             				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
     1824             			}
     1825             
     1826             			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
     1827             			double sum = rv[row] - totalContribution;
     1828             
     1829             			sum += xv[row] * currentDiagonal;
     1830             			xv[row] = sum / currentDiagonal;
     1831             		}
     1832             		}
     1833             	}
     1834             
     1835             	/*
     1836             	 * BACKWARD SWEEP
     1837             	 */
     1838             	for ( local_int_t l = A.tdg.size()-1; l >= 0; l-- ) {
     1839             		local_int_t tdgLevelSize = A.tdg[l].size();
     1840             		if((tdgLevelSize%2) == 0) {		
     1841             #ifndef HPCG_NO_OPENMP
     1842             #pragma omp parallel for SCH_SYMGS(runtime)
     1843             #endif
     1844             		for ( local_int_t i = tdgLevelSize-1; i >= 0; i-= 2 ) {
     1845             			local_int_t row_1 = A.tdg[l][i];
     1846             			local_int_t row_2 = A.tdg[l][i-1];
     1847             			const double * const currentValues_1 = A.matrixValues[row_1];
     1848             			const double * const currentValues_2 = A.matrixValues[row_2];
     1849             			const local_int_t * const currentColIndices_1 = A.mtxIndL[row_1];
     1850             			const local_int_t * const currentColIndices_2 = A.mtxIndL[row_2];
     1851             			const int currentNumberOfNonzeros_1 = A.nonzerosInRow[row_1];
     1852             			const int currentNumberOfNonzeros_2 = A.nonzerosInRow[row_2];
     1853             			const double currentDiagonal_1 = matrixDiagonal[row_1][0];
     1854             			const double currentDiagonal_2 = matrixDiagonal[row_2][0];
     1855             			svfloat64_t contribs_1 = svdup_f64(0.0);
     1856             			svfloat64_t contribs_2 = svdup_f64(0.0);
     1857             
     1858             			const int maxNumberOfNonzeros = std::max(currentNumberOfNonzeros_1, currentNumberOfNonzeros_2);				
     1859             							
     1860             			for ( local_int_t j = 0; j < maxNumberOfNonzeros; j += svcntd()) {
     1861             				svbool_t pg_1 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_1);
     1862             				svbool_t pg_2 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_2);
     1863             				
     1864             				svfloat64_t mtxValues_1 = svld1_f64(pg_1, &currentValues_1[j]);
     1865             				svfloat64_t mtxValues_2 = svld1_f64(pg_2, &currentValues_2[j]);
     1866             				svuint64_t indices_1 = svld1sw_u64(pg_1, &currentColIndices_1[j]);
     1867             				svuint64_t indices_2 = svld1sw_u64(pg_2, &currentColIndices_2[j]);
     1868             				svfloat64_t xvv_1 = svld1_gather_u64index_f64(pg_1, xv, indices_1);
     1869             				svfloat64_t xvv_2 = svld1_gather_u64index_f64(pg_2, xv, indices_2);
     1870             
     1871             				contribs_1 = svmla_f64_m(pg_1, contribs_1, xvv_1, mtxValues_1);
     1872             				contribs_2 = svmla_f64_m(pg_2, contribs_2, xvv_2, mtxValues_2);
     1873             			}
     1874             
     1875             			double totalContribution_1 = svaddv_f64(svptrue_b64(), contribs_1);
     1876             			double totalContribution_2 = svaddv_f64(svptrue_b64(), contribs_2);
     1877             			double sum_1 = rv[row_1] - totalContribution_1;
     1878             			double sum_2 = rv[row_2] - totalContribution_2;
     1879             
     1880             			sum_1 += xv[row_1] * currentDiagonal_1;
     1881             			sum_2 += xv[row_2] * currentDiagonal_2;
     1882             			xv[row_1] = sum_1 / currentDiagonal_1;
     1883             			xv[row_2] = sum_2 / currentDiagonal_2;
     1884             		}
     1885             		}
     1886             		else
     1887             		{
     1888             #ifndef HPCG_NO_OPENMP
     1889             #pragma omp parallel for SCH_SYMGS(runtime)
     1890             #endif
     1891             		for ( local_int_t i = tdgLevelSize-1; i >= 0; i-- ) {
     1892             			local_int_t row = A.tdg[l][i];
     1893             			const double * const currentValues = A.matrixValues[row];
     1894             			const local_int_t * const currentColIndices = A.mtxIndL[row];
     1895             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     1896             			const double currentDiagonal = matrixDiagonal[row][0];
     1897             			svfloat64_t contribs = svdup_f64(0.0);
     1898             
     1899             			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
     1900             				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
     1901             				
     1902             				svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
     1903             				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
     1904             				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
     1905             
     1906             				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
     1907             			}
     1908             
     1909             			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
     1910             			double sum = rv[row] - totalContribution;
     1911             
     1912             			sum += xv[row] * currentDiagonal;
     1913             			xv[row] = sum / currentDiagonal;
     1914             		}
     1915             		}
     1916             	}
     1917             }
     1918             
     1919             inline void SYMGS_VERSION_2(const SparseMatrix& A, double * const& xv, const double * const& rv) {
     1920             	
     1921             	double **matrixDiagonal = A.matrixDiagonal;
     1922             
     1923             	/*
     1924             	 * FORWARD SWEEP
     1925             	 */
     1926             	for ( local_int_t l = 0; l < A.tdg.size(); l++ ) {
     1927             		local_int_t tdgLevelSize = A.tdg[l].size();
     1928             		local_int_t maxLevelSize = 2*(tdgLevelSize / 2);
     1929             
     1930             #ifndef HPCG_NO_OPENMP
     1931             	#pragma omp parallel
     1932             	{
     1933             	#pragma omp for nowait SCH_SYMGS(runtime)
     1934             #endif
     1935             		for ( local_int_t i = 0; i < maxLevelSize; i+=2 ) {
     1936             			local_int_t row_1 = A.tdg[l][i];
     1937             			local_int_t row_2 = A.tdg[l][i+1];
     1938             			const double * const currentValues_1 = A.matrixValues[row_1];
     1939             			const local_int_t * const currentColIndices_1 = A.mtxIndL[row_1];
     1940             			const int currentNumberOfNonzeros_1 = A.nonzerosInRow[row_1];
     1941             			const double currentDiagonal_1 = matrixDiagonal[row_1][0];
     1942             			svfloat64_t contribs_1 = svdup_f64(0.0);
     1943             
     1944             			const double * const currentValues_2 = A.matrixValues[row_2];
     1945             			const local_int_t * const currentColIndices_2 = A.mtxIndL[row_2];
     1946             			const int currentNumberOfNonzeros_2 = A.nonzerosInRow[row_2];
     1947             			const double currentDiagonal_2 = matrixDiagonal[row_2][0];
     1948             			svfloat64_t contribs_2 = svdup_f64(0.0);
     1949             			
     1950             			const int maxNumberOfNonzeros = std::max(currentNumberOfNonzeros_1, currentNumberOfNonzeros_2);
     1951             
     1952             			for ( local_int_t j = 0; j < maxNumberOfNonzeros; j += svcntd()) {
     1953             				svbool_t pg_1 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_1);
     1954             				
     1955             				svfloat64_t mtxValues_1 = svld1_f64(pg_1, &currentValues_1[j]);
     1956             				svuint64_t indices_1 = svld1sw_u64(pg_1, &currentColIndices_1[j]);
     1957             				svfloat64_t xvv_1 = svld1_gather_u64index_f64(pg_1, xv, indices_1);
     1958             
     1959             				contribs_1 = svmla_f64_m(pg_1, contribs_1, xvv_1, mtxValues_1);
     1960             
     1961             				svbool_t pg_2 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_2);
     1962             				svfloat64_t mtxValues_2 = svld1_f64(pg_2, &currentValues_2[j]);
     1963             				svuint64_t indices_2 = svld1sw_u64(pg_2, &currentColIndices_2[j]);
     1964             				svfloat64_t xvv_2 = svld1_gather_u64index_f64(pg_2, xv, indices_2);
     1965             
     1966             				contribs_2 = svmla_f64_m(pg_2, contribs_2, xvv_2, mtxValues_2);
     1967             			}
     1968             
     1969             			double totalContribution_1 = svaddv_f64(svptrue_b64(), contribs_1);
     1970             			double sum_1 = rv[row_1] - totalContribution_1;
     1971             
     1972             			sum_1 += xv[row_1] * currentDiagonal_1;
     1973             			xv[row_1] = sum_1 / currentDiagonal_1;
     1974             
     1975             			double totalContribution_2 = svaddv_f64(svptrue_b64(), contribs_2);
     1976             			double sum_2 = rv[row_2] - totalContribution_2;
     1977             
     1978             			sum_2 += xv[row_2] * currentDiagonal_2;
     1979             			xv[row_2] = sum_2 / currentDiagonal_2;
     1980             		}
     1981             
     1982             		#pragma omp single 
     1983             		if (maxLevelSize < tdgLevelSize) {
     1984             			local_int_t i = maxLevelSize;
     1985             
     1986             			local_int_t row = A.tdg[l][i];
     1987             			const double * const currentValues = A.matrixValues[row];
     1988             			const local_int_t * const currentColIndices = A.mtxIndL[row];
     1989             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     1990             			const double currentDiagonal = matrixDiagonal[row][0];
     1991             			svfloat64_t contribs = svdup_f64(0.0);
     1992             
     1993             			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
     1994             				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
     1995             				
     1996             				svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
     1997             				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
     1998             				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
     1999             
     2000             				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
     2001             			}
     2002             
     2003             			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
     2004             			double sum = rv[row] - totalContribution;
     2005             
     2006             			sum += xv[row] * currentDiagonal;
     2007             			xv[row] = sum / currentDiagonal;
     2008             		}
     2009             #ifndef HPCG_NO_OPENMP
     2010             	}
     2011             #endif
     2012             	}
     2013             
     2014             	/*
     2015             	 * BACKWARD SWEEP
     2016             	 */
     2017             	for ( local_int_t l = A.tdg.size()-1; l >= 0; l-- ) {
     2018             		local_int_t tdgLevelSize = A.tdg[l].size();
     2019             		local_int_t maxLevelSize = 2*(tdgLevelSize / 2);
     2020             
     2021             #ifndef HPCG_NO_OPENMP
     2022             #pragma omp parallel 
     2023             	{
     2024             		#pragma omp single nowait 
     2025             		{
     2026             #endif
     2027             		if (tdgLevelSize > maxLevelSize) {
     2028             			local_int_t i = maxLevelSize-1;
     2029             
     2030             			local_int_t row = A.tdg[l][i];
     2031             			const double * const currentValues = A.matrixValues[row];
     2032             			const local_int_t * const currentColIndices = A.mtxIndL[row];
     2033             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     2034             			const double currentDiagonal = matrixDiagonal[row][0];
     2035             			svfloat64_t contribs = svdup_f64(0.0);
     2036             
     2037             			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
     2038             				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
     2039             				
     2040             				svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
     2041             				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
     2042             				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
     2043             
     2044             				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
     2045             			}
     2046             
     2047             			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
     2048             			double sum = rv[row] - totalContribution;
     2049             
     2050             			sum += xv[row] * currentDiagonal;
     2051             			xv[row] = sum / currentDiagonal;
     2052             		}
     2053             #ifndef HPCG_NO_OPENMP
     2054             		}
     2055             #pragma omp for SCH_SYMGS(runtime)
     2056             #endif
     2057             		for ( local_int_t i = maxLevelSize-1; i >= 0; i-= 2 ) {
     2058             			local_int_t row_1 = A.tdg[l][i];
     2059             			local_int_t row_2 = A.tdg[l][i-1];
     2060             			const double * const currentValues_1 = A.matrixValues[row_1];
     2061             			const double * const currentValues_2 = A.matrixValues[row_2];
     2062             			const local_int_t * const currentColIndices_1 = A.mtxIndL[row_1];
     2063             			const local_int_t * const currentColIndices_2 = A.mtxIndL[row_2];
     2064             			const int currentNumberOfNonzeros_1 = A.nonzerosInRow[row_1];
     2065             			const int currentNumberOfNonzeros_2 = A.nonzerosInRow[row_2];
     2066             			const double currentDiagonal_1 = matrixDiagonal[row_1][0];
     2067             			const double currentDiagonal_2 = matrixDiagonal[row_2][0];
     2068             			svfloat64_t contribs_1 = svdup_f64(0.0);
     2069             			svfloat64_t contribs_2 = svdup_f64(0.0);
     2070             
     2071             			const int maxNumberOfNonzeros = std::max(currentNumberOfNonzeros_1, currentNumberOfNonzeros_2);				
     2072             							
     2073             			for ( local_int_t j = 0; j < maxNumberOfNonzeros; j += svcntd()) {
     2074             				svbool_t pg_1 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_1);
     2075             				svbool_t pg_2 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_2);
     2076             				
     2077             				svfloat64_t mtxValues_1 = svld1_f64(pg_1, &currentValues_1[j]);
     2078             				svfloat64_t mtxValues_2 = svld1_f64(pg_2, &currentValues_2[j]);
     2079             				svuint64_t indices_1 = svld1sw_u64(pg_1, &currentColIndices_1[j]);
     2080             				svuint64_t indices_2 = svld1sw_u64(pg_2, &currentColIndices_2[j]);
     2081             				svfloat64_t xvv_1 = svld1_gather_u64index_f64(pg_1, xv, indices_1);
     2082             				svfloat64_t xvv_2 = svld1_gather_u64index_f64(pg_2, xv, indices_2);
     2083             
     2084             				contribs_1 = svmla_f64_m(pg_1, contribs_1, xvv_1, mtxValues_1);
     2085             				contribs_2 = svmla_f64_m(pg_2, contribs_2, xvv_2, mtxValues_2);
     2086             			}
     2087             
     2088             			double totalContribution_1 = svaddv_f64(svptrue_b64(), contribs_1);
     2089             			double totalContribution_2 = svaddv_f64(svptrue_b64(), contribs_2);
     2090             			double sum_1 = rv[row_1] - totalContribution_1;
     2091             			double sum_2 = rv[row_2] - totalContribution_2;
     2092             
     2093             			sum_1 += xv[row_1] * currentDiagonal_1;
     2094             			sum_2 += xv[row_2] * currentDiagonal_2;
     2095             			xv[row_1] = sum_1 / currentDiagonal_1;
     2096             			xv[row_2] = sum_2 / currentDiagonal_2;
     2097             		}
     2098             #ifndef HPCG_NO_OPENMP
     2099             	}
     2100             #endif
     2101             	}
     2102             }
     2103             
     2104             inline void SYMGS_VERSION_3(const SparseMatrix& A, double * const& prxv, const double * const& rv) {
     2105             	
     2106             	double **matrixDiagonal = A.matrixDiagonal;
     2107             	double *xv = prxv;
     2108             
     2109             //#pragma statement scache_isolate_way L2=10
     2110             //#pragma statement scache_isolate_assign xv
     2111             #ifndef HPCG_NO_OPENMP
     2112             	#pragma omp parallel
     2113             	{
     2114             		local_int_t numThreads = omp_get_num_threads();
     2115             #endif
     2116             	/*
     2117             	 * FORWARD SWEEP
     2118             	 */
     2119             	for ( local_int_t l = 0; l < A.tdg.size(); l++ ) {
     2120             		local_int_t tdgLevelSize = A.tdg[l].size();
     2121             		local_int_t maxLevelSize = 4*(tdgLevelSize / 4);
     2122             
     2123             #ifdef MANUAL_TASK_DISTRIBUTION
     2124             		//at least 8 tasks per thread 
     2125             		local_int_t maxTasksPerThread = std::max((tdgLevelSize+numThreads-1)/numThreads, 8);
     2126             		local_int_t groupedTasksPerThread = ((maxTasksPerThread+7)/8)*8;
     2127             		local_int_t threadId = omp_get_thread_num();
     2128             		local_int_t minValue = groupedTasksPerThread*threadId;
     2129             		local_int_t maxValue = minValue+groupedTasksPerThread;
     2130             		maxLevelSize = std::min(maxValue, maxLevelSize);
     2131             		tdgLevelSize = std::min(maxValue, tdgLevelSize);
     2132             
     2133             		#pragma fj loop zfill			
     2134             		#pragma loop nounroll
     2135             		for ( local_int_t i = minValue; i < maxLevelSize; i+=4 ) {
     2136             #else
     2137             #ifndef HPCG_NO_OPENMP
     2138             	#pragma fj loop zfill			
     2139             	#pragma loop nounroll
     2140             	#pragma omp for nowait SCH_SYMGS(runtime)
     2141             #endif
     2142             		for ( local_int_t i = 0; i < maxLevelSize; i+=4 ) {
     2143             #endif
     2144             			local_int_t row_1 = A.tdg[l][i];
     2145             			local_int_t row_2 = A.tdg[l][i+1];
     2146             			local_int_t row_3 = A.tdg[l][i+2];
     2147             			local_int_t row_4 = A.tdg[l][i+3];
     2148             			const double * const currentValues_1 = A.matrixValues[row_1];
     2149             			const local_int_t * const currentColIndices_1 = A.mtxIndL[row_1];
     2150             			const int currentNumberOfNonzeros_1 = A.nonzerosInRow[row_1];
     2151             			const double currentDiagonal_1 = matrixDiagonal[row_1][0];
     2152             			svfloat64_t contribs_1 = svdup_f64(0.0);
     2153             
     2154             			const double * const currentValues_2 = A.matrixValues[row_2];
     2155             			const local_int_t * const currentColIndices_2 = A.mtxIndL[row_2];
     2156             			const int currentNumberOfNonzeros_2 = A.nonzerosInRow[row_2];
     2157             			const double currentDiagonal_2 = matrixDiagonal[row_2][0];
     2158             			svfloat64_t contribs_2 = svdup_f64(0.0);
     2159             
     2160             			const double * const currentValues_3 = A.matrixValues[row_3];
     2161             			const local_int_t * const currentColIndices_3 = A.mtxIndL[row_3];
     2162             			const int currentNumberOfNonzeros_3 = A.nonzerosInRow[row_3];
     2163             			const double currentDiagonal_3 = matrixDiagonal[row_3][0];
     2164             			svfloat64_t contribs_3 = svdup_f64(0.0);
     2165             
     2166             			const double * const currentValues_4 = A.matrixValues[row_4];
     2167             			const local_int_t * const currentColIndices_4 = A.mtxIndL[row_4];
     2168             			const int currentNumberOfNonzeros_4 = A.nonzerosInRow[row_4];
     2169             			const double currentDiagonal_4 = matrixDiagonal[row_4][0];
     2170             			svfloat64_t contribs_4 = svdup_f64(0.0);
     2171             
     2172             			const int maxNumberOfNonzeros1 = std::max(currentNumberOfNonzeros_1, currentNumberOfNonzeros_2);
     2173             			const int maxNumberOfNonzeros2 = std::max(currentNumberOfNonzeros_3, currentNumberOfNonzeros_4);
     2174             			const int maxNumberOfNonzeros = std::max(maxNumberOfNonzeros1, maxNumberOfNonzeros2);
     2175             
     2176             			for ( local_int_t j = 0; j < maxNumberOfNonzeros; j += svcntd()) {
     2177             				svbool_t pg_1 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_1);
     2178             				
     2179             				svfloat64_t mtxValues_1 = svld1_f64(pg_1, &currentValues_1[j]);
     2180             				svuint64_t indices_1 = svld1sw_u64(pg_1, &currentColIndices_1[j]);
     2181             				svfloat64_t xvv_1 = svld1_gather_u64index_f64(pg_1, xv, indices_1);
     2182             
     2183             				contribs_1 = svmla_f64_m(pg_1, contribs_1, xvv_1, mtxValues_1);
     2184             
     2185             				svbool_t pg_2 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_2);
     2186             				svfloat64_t mtxValues_2 = svld1_f64(pg_2, &currentValues_2[j]);
     2187             				svuint64_t indices_2 = svld1sw_u64(pg_2, &currentColIndices_2[j]);
     2188             				svfloat64_t xvv_2 = svld1_gather_u64index_f64(pg_2, xv, indices_2);
     2189             
     2190             				contribs_2 = svmla_f64_m(pg_2, contribs_2, xvv_2, mtxValues_2);
     2191             
     2192             				svbool_t pg_3 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_3);
     2193             				svfloat64_t mtxValues_3 = svld1_f64(pg_3, &currentValues_3[j]);
     2194             				svuint64_t indices_3 = svld1sw_u64(pg_3, &currentColIndices_3[j]);
     2195             				svfloat64_t xvv_3 = svld1_gather_u64index_f64(pg_3, xv, indices_3);
     2196             
     2197             				contribs_3 = svmla_f64_m(pg_3, contribs_3, xvv_3, mtxValues_3);
     2198             
     2199             				svbool_t pg_4 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_4);
     2200             				svfloat64_t mtxValues_4 = svld1_f64(pg_4, &currentValues_4[j]);
     2201             				svuint64_t indices_4 = svld1sw_u64(pg_4, &currentColIndices_4[j]);
     2202             				svfloat64_t xvv_4 = svld1_gather_u64index_f64(pg_4, xv, indices_4);
     2203             
     2204             				contribs_4 = svmla_f64_m(pg_4, contribs_4, xvv_4, mtxValues_4);
     2205             			}
     2206             
     2207             			double totalContribution_1 = svaddv_f64(svptrue_b64(), contribs_1);
     2208             			double sum_1 = rv[row_1] - totalContribution_1;
     2209             
     2210             			sum_1 += xv[row_1] * currentDiagonal_1;
     2211             			xv[row_1] = sum_1 / currentDiagonal_1;
     2212             
     2213             			double totalContribution_2 = svaddv_f64(svptrue_b64(), contribs_2);
     2214             			double sum_2 = rv[row_2] - totalContribution_2;
     2215             
     2216             			sum_2 += xv[row_2] * currentDiagonal_2;
     2217             			xv[row_2] = sum_2 / currentDiagonal_2;
     2218             
     2219             			double totalContribution_3 = svaddv_f64(svptrue_b64(), contribs_3);
     2220             			double sum_3 = rv[row_3] - totalContribution_3;
     2221             
     2222             			sum_3 += xv[row_3] * currentDiagonal_3;
     2223             			xv[row_3] = sum_3 / currentDiagonal_3;
     2224             
     2225             			double totalContribution_4 = svaddv_f64(svptrue_b64(), contribs_4);
     2226             			double sum_4 = rv[row_4] - totalContribution_4;
     2227             
     2228             			sum_4 += xv[row_4] * currentDiagonal_4;
     2229             			xv[row_4] = sum_4 / currentDiagonal_4;
     2230             		}
     2231             
     2232             //#pragma omp single
     2233             		if (maxLevelSize < tdgLevelSize) {
     2234             /************
     2235             #ifndef HPCG_NO_OPENMP
     2236             //#pragma loop nounroll
     2237             #pragma omp for SCH_SYMGS(runtime)
     2238             #endif
     2239             		for ( local_int_t i = maxLevelSize; i < tdgLevelSize; i++ ) {
     2240             
     2241             			local_int_t row = A.tdg[l][i];
     2242             			const double * const currentValues = A.matrixValues[row];
     2243             			const local_int_t * const currentColIndices = A.mtxIndL[row];
     2244             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     2245             			const double currentDiagonal = matrixDiagonal[row][0];
     2246             			svfloat64_t contribs = svdup_f64(0.0);
     2247             
     2248             			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
     2249             				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
     2250             				
     2251             				svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
     2252             				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
     2253             				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
     2254             
     2255             				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
     2256             			}
     2257             
     2258             			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
     2259             			double sum = rv[row] - totalContribution;
     2260             
     2261             			sum += xv[row] * currentDiagonal;
     2262             			xv[row] = sum / currentDiagonal;
     2263             		}
     2264             *******/
     2265             		#pragma omp sections nowait
     2266             		{
     2267             			#pragma fj loop zfill			
     2268             			#pragma omp section 
     2269             			{
     2270             				local_int_t i = maxLevelSize;
     2271             				local_int_t row = A.tdg[l][i];
     2272             				const double * const currentValues = A.matrixValues[row];
     2273             				const local_int_t * const currentColIndices = A.mtxIndL[row];
     2274             				const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     2275             				const double currentDiagonal = matrixDiagonal[row][0];
     2276             				svfloat64_t contribs = svdup_f64(0.0);
     2277             
     2278             				for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
     2279             					svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
     2280             					
     2281             					svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
     2282             					svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
     2283             					svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
     2284             
     2285             					contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
     2286             				}
     2287             
     2288             				double totalContribution = svaddv_f64(svptrue_b64(), contribs);
     2289             				double sum = rv[row] - totalContribution;
     2290             
     2291             				sum += xv[row] * currentDiagonal;
     2292             				xv[row] = sum / currentDiagonal;
     2293             			}
     2294             			#pragma fj loop zfill			
     2295             			#pragma omp section 
     2296             			{
     2297             				local_int_t i = maxLevelSize + 1;
     2298             				if (i < tdgLevelSize) {
     2299             				local_int_t row = A.tdg[l][i];
     2300             				const double * const currentValues = A.matrixValues[row];
     2301             				const local_int_t * const currentColIndices = A.mtxIndL[row];
     2302             				const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     2303             				const double currentDiagonal = matrixDiagonal[row][0];
     2304             				svfloat64_t contribs = svdup_f64(0.0);
     2305             
     2306             				for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
     2307             					svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
     2308             					
     2309             					svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
     2310             					svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
     2311             					svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
     2312             
     2313             					contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
     2314             				}
     2315             
     2316             				double totalContribution = svaddv_f64(svptrue_b64(), contribs);
     2317             				double sum = rv[row] - totalContribution;
     2318             
     2319             				sum += xv[row] * currentDiagonal;
     2320             				xv[row] = sum / currentDiagonal;
     2321             				}
     2322             			}
     2323             			#pragma fj loop zfill			
     2324             			#pragma omp section 
     2325             			{
     2326             				local_int_t i = maxLevelSize + 2;
     2327             				if (i < tdgLevelSize) {
     2328             				local_int_t row = A.tdg[l][i];
     2329             				const double * const currentValues = A.matrixValues[row];
     2330             				const local_int_t * const currentColIndices = A.mtxIndL[row];
     2331             				const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     2332             				const double currentDiagonal = matrixDiagonal[row][0];
     2333             				svfloat64_t contribs = svdup_f64(0.0);
     2334             
     2335             				for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
     2336             					svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
     2337             					
     2338             					svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
     2339             					svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
     2340             					svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
     2341             
     2342             					contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
     2343             				}
     2344             
     2345             				double totalContribution = svaddv_f64(svptrue_b64(), contribs);
     2346             				double sum = rv[row] - totalContribution;
     2347             
     2348             				sum += xv[row] * currentDiagonal;
     2349             				xv[row] = sum / currentDiagonal;
     2350             				}
     2351             			}
     2352             		}
     2353             
     2354             /***********/
     2355             #ifndef HPCG_NO_OPENMP
     2356             	}
     2357             	#pragma omp barrier
     2358             #endif
     2359             	}
     2360             
     2361             	/*
     2362             	 * BACKWARD SWEEP
     2363             	 */
     2364             	for ( local_int_t l = A.tdg.size()-1; l >= 0; l-- ) {
     2365             		local_int_t tdgLevelSize = A.tdg[l].size();
     2366             		local_int_t maxLevelSize = 4*(tdgLevelSize / 4);
     2367             
     2368             #ifndef HPCG_NO_OPENMP
     2369             		//#pragma omp single nowait 
     2370             		//{
     2371             		#pragma fj loop zfill			
     2372             		#pragma loop nounroll
     2373             		#pragma omp for nowait SCH_SYMGS(runtime)
     2374             #endif
     2375             		for ( local_int_t i = tdgLevelSize-1; i >= maxLevelSize; i-- ) {
     2376             			local_int_t row = A.tdg[l][i];
     2377             			const double * const currentValues = A.matrixValues[row];
     2378             			const local_int_t * const currentColIndices = A.mtxIndL[row];
     2379             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     2380             			const double currentDiagonal = matrixDiagonal[row][0];
     2381             			svfloat64_t contribs = svdup_f64(0.0);
     2382             
     2383             			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
     2384             				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
     2385             				
     2386             				svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
     2387             				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
     2388             				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
     2389             
     2390             				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
     2391             			}
     2392             
     2393             			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
     2394             			double sum = rv[row] - totalContribution;
     2395             
     2396             			sum += xv[row] * currentDiagonal;
     2397             			xv[row] = sum / currentDiagonal;
     2398             		}
     2399             
     2400             #ifndef HPCG_NO_OPENMP
     2401             		//}
     2402             #pragma fj loop zfill			
     2403             #pragma loop nounroll
     2404             #pragma omp for SCH_SYMGS(runtime)
     2405             #endif
     2406             		for ( local_int_t i = maxLevelSize-1; i >= 0; i-= 4 ) {
     2407             			local_int_t row_1 = A.tdg[l][i];
     2408             			local_int_t row_2 = A.tdg[l][i-1];
     2409             			local_int_t row_3 = A.tdg[l][i-2];
     2410             			local_int_t row_4 = A.tdg[l][i-3];
     2411             			const double * const currentValues_1 = A.matrixValues[row_1];
     2412             			const double * const currentValues_2 = A.matrixValues[row_2];
     2413             			const double * const currentValues_3 = A.matrixValues[row_3];
     2414             			const double * const currentValues_4 = A.matrixValues[row_4];
     2415             			const local_int_t * const currentColIndices_1 = A.mtxIndL[row_1];
     2416             			const local_int_t * const currentColIndices_2 = A.mtxIndL[row_2];
     2417             			const local_int_t * const currentColIndices_3 = A.mtxIndL[row_3];
     2418             			const local_int_t * const currentColIndices_4 = A.mtxIndL[row_4];
     2419             			const int currentNumberOfNonzeros_1 = A.nonzerosInRow[row_1];
     2420             			const int currentNumberOfNonzeros_2 = A.nonzerosInRow[row_2];
     2421             			const int currentNumberOfNonzeros_3 = A.nonzerosInRow[row_3];
     2422             			const int currentNumberOfNonzeros_4 = A.nonzerosInRow[row_4];
     2423             			const double currentDiagonal_1 = matrixDiagonal[row_1][0];
     2424             			const double currentDiagonal_2 = matrixDiagonal[row_2][0];
     2425             			const double currentDiagonal_3 = matrixDiagonal[row_3][0];
     2426             			const double currentDiagonal_4 = matrixDiagonal[row_4][0];
     2427             			svfloat64_t contribs_1 = svdup_f64(0.0);
     2428             			svfloat64_t contribs_2 = svdup_f64(0.0);
     2429             			svfloat64_t contribs_3 = svdup_f64(0.0);
     2430             			svfloat64_t contribs_4 = svdup_f64(0.0);
     2431             
     2432             			const int maxNumberOfNonzeros1 = std::max(currentNumberOfNonzeros_1, currentNumberOfNonzeros_2);				
     2433             			const int maxNumberOfNonzeros2 = std::max(currentNumberOfNonzeros_3, currentNumberOfNonzeros_4);				
     2434             			const int maxNumberOfNonzeros = std::max(maxNumberOfNonzeros1, maxNumberOfNonzeros2);				
     2435             							
     2436             			for ( local_int_t j = 0; j < maxNumberOfNonzeros; j += svcntd()) {
     2437             				svbool_t pg_1 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_1);
     2438             				svbool_t pg_2 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_2);
     2439             				svbool_t pg_3 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_3);
     2440             				svbool_t pg_4 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_4);
     2441             				
     2442             				svfloat64_t mtxValues_1 = svld1_f64(pg_1, &currentValues_1[j]);
     2443             				svfloat64_t mtxValues_2 = svld1_f64(pg_2, &currentValues_2[j]);
     2444             				svfloat64_t mtxValues_3 = svld1_f64(pg_3, &currentValues_3[j]);
     2445             				svfloat64_t mtxValues_4 = svld1_f64(pg_4, &currentValues_4[j]);
     2446             				svuint64_t indices_1 = svld1sw_u64(pg_1, &currentColIndices_1[j]);
     2447             				svuint64_t indices_2 = svld1sw_u64(pg_2, &currentColIndices_2[j]);
     2448             				svuint64_t indices_3 = svld1sw_u64(pg_3, &currentColIndices_3[j]);
     2449             				svuint64_t indices_4 = svld1sw_u64(pg_4, &currentColIndices_4[j]);
     2450             				svfloat64_t xvv_1 = svld1_gather_u64index_f64(pg_1, xv, indices_1);
     2451             				svfloat64_t xvv_2 = svld1_gather_u64index_f64(pg_2, xv, indices_2);
     2452             				svfloat64_t xvv_3 = svld1_gather_u64index_f64(pg_3, xv, indices_3);
     2453             				svfloat64_t xvv_4 = svld1_gather_u64index_f64(pg_4, xv, indices_4);
     2454             
     2455             				contribs_1 = svmla_f64_m(pg_1, contribs_1, xvv_1, mtxValues_1);
     2456             				contribs_2 = svmla_f64_m(pg_2, contribs_2, xvv_2, mtxValues_2);
     2457             				contribs_3 = svmla_f64_m(pg_3, contribs_3, xvv_3, mtxValues_3);
     2458             				contribs_4 = svmla_f64_m(pg_4, contribs_4, xvv_4, mtxValues_4);
     2459             			}
     2460             
     2461             			double totalContribution_1 = svaddv_f64(svptrue_b64(), contribs_1);
     2462             			double totalContribution_2 = svaddv_f64(svptrue_b64(), contribs_2);
     2463             			double totalContribution_3 = svaddv_f64(svptrue_b64(), contribs_3);
     2464             			double totalContribution_4 = svaddv_f64(svptrue_b64(), contribs_4);
     2465             			double sum_1 = rv[row_1] - totalContribution_1;
     2466             			double sum_2 = rv[row_2] - totalContribution_2;
     2467             			double sum_3 = rv[row_3] - totalContribution_3;
     2468             			double sum_4 = rv[row_4] - totalContribution_4;
     2469             
     2470             			sum_1 += xv[row_1] * currentDiagonal_1;
     2471             			sum_2 += xv[row_2] * currentDiagonal_2;
     2472             			sum_3 += xv[row_3] * currentDiagonal_3;
     2473             			sum_4 += xv[row_4] * currentDiagonal_4;
     2474             			xv[row_1] = sum_1 / currentDiagonal_1;
     2475             			xv[row_2] = sum_2 / currentDiagonal_2;
     2476             			xv[row_3] = sum_3 / currentDiagonal_3;
     2477             			xv[row_4] = sum_4 / currentDiagonal_4;
     2478             		}
     2479             #ifndef HPCG_NO_OPENMP
     2480             	}
     2481             #endif
     2482             	}
     2483             
     2484             //#pragma statement end_scache_isolate_assign
     2485             //#pragma statement end_scache_isolate_way	
     2486             }
     2487             /////////////
     2488             inline void SYMGS_VERSION_4(const SparseMatrix& A, double * const& xv, const double * const& rv) {
     2489             	
     2490             	double **matrixDiagonal = A.matrixDiagonal;
     2491             
     2492             	/*
     2493             	 * FORWARD SWEEP
     2494             	 */
     2495             	for ( local_int_t l = 0; l < A.tdg.size(); l++ ) {
     2496             		local_int_t tdgLevelSize = A.tdg[l].size();
     2497             		local_int_t maxLevelSize = 6*(tdgLevelSize / 6);
     2498             
     2499             #ifndef HPCG_NO_OPENMP
     2500             	#pragma omp parallel
     2501             	{
     2502             	#pragma omp for nowait SCH_SYMGS(runtime)
     2503             #endif
     2504             		for ( local_int_t i = 0; i < maxLevelSize; i+=6 ) {
     2505             			local_int_t row_1 = A.tdg[l][i];
     2506             			local_int_t row_2 = A.tdg[l][i+1];
     2507             			local_int_t row_3 = A.tdg[l][i+2];
     2508             			local_int_t row_4 = A.tdg[l][i+3];
     2509             			local_int_t row_5 = A.tdg[l][i+4];
     2510             			local_int_t row_6 = A.tdg[l][i+5];
     2511             			const double * const currentValues_1 = A.matrixValues[row_1];
     2512             			const local_int_t * const currentColIndices_1 = A.mtxIndL[row_1];
     2513             			const int currentNumberOfNonzeros_1 = A.nonzerosInRow[row_1];
     2514             			const double currentDiagonal_1 = matrixDiagonal[row_1][0];
     2515             			svfloat64_t contribs_1 = svdup_f64(0.0);
     2516             
     2517             			const double * const currentValues_2 = A.matrixValues[row_2];
     2518             			const local_int_t * const currentColIndices_2 = A.mtxIndL[row_2];
     2519             			const int currentNumberOfNonzeros_2 = A.nonzerosInRow[row_2];
     2520             			const double currentDiagonal_2 = matrixDiagonal[row_2][0];
     2521             			svfloat64_t contribs_2 = svdup_f64(0.0);
     2522             
     2523             			const double * const currentValues_3 = A.matrixValues[row_3];
     2524             			const local_int_t * const currentColIndices_3 = A.mtxIndL[row_3];
     2525             			const int currentNumberOfNonzeros_3 = A.nonzerosInRow[row_3];
     2526             			const double currentDiagonal_3 = matrixDiagonal[row_3][0];
     2527             			svfloat64_t contribs_3 = svdup_f64(0.0);
     2528             
     2529             			const double * const currentValues_4 = A.matrixValues[row_4];
     2530             			const local_int_t * const currentColIndices_4 = A.mtxIndL[row_4];
     2531             			const int currentNumberOfNonzeros_4 = A.nonzerosInRow[row_4];
     2532             			const double currentDiagonal_4 = matrixDiagonal[row_4][0];
     2533             			svfloat64_t contribs_4 = svdup_f64(0.0);
     2534             
     2535             			const double * const currentValues_5 = A.matrixValues[row_5];
     2536             			const local_int_t * const currentColIndices_5 = A.mtxIndL[row_5];
     2537             			const int currentNumberOfNonzeros_5 = A.nonzerosInRow[row_5];
     2538             			const double currentDiagonal_5 = matrixDiagonal[row_5][0];
     2539             			svfloat64_t contribs_5 = svdup_f64(0.0);
     2540             
     2541             			const double * const currentValues_6 = A.matrixValues[row_6];
     2542             			const local_int_t * const currentColIndices_6 = A.mtxIndL[row_6];
     2543             			const int currentNumberOfNonzeros_6 = A.nonzerosInRow[row_6];
     2544             			const double currentDiagonal_6 = matrixDiagonal[row_6][0];
     2545             			svfloat64_t contribs_6 = svdup_f64(0.0);
     2546             
     2547             			const int maxNumberOfNonzeros1 = std::max(currentNumberOfNonzeros_1, currentNumberOfNonzeros_2);
     2548             			const int maxNumberOfNonzeros2 = std::max(currentNumberOfNonzeros_3, currentNumberOfNonzeros_4);
     2549             			const int maxNumberOfNonzeros3 = std::max(currentNumberOfNonzeros_5, currentNumberOfNonzeros_6);
     2550             			const int maxNumberOfNonzeros4 = std::max(maxNumberOfNonzeros1, maxNumberOfNonzeros2);
     2551             			const int maxNumberOfNonzeros = std::max(maxNumberOfNonzeros4, maxNumberOfNonzeros3);
     2552             
     2553             			for ( local_int_t j = 0; j < maxNumberOfNonzeros; j += svcntd()) {
     2554             				svbool_t pg_1 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_1);		
     2555             				svfloat64_t mtxValues_1 = svld1_f64(pg_1, &currentValues_1[j]);
     2556             				svuint64_t indices_1 = svld1sw_u64(pg_1, &currentColIndices_1[j]);
     2557             				svfloat64_t xvv_1 = svld1_gather_u64index_f64(pg_1, xv, indices_1);
     2558             
     2559             				contribs_1 = svmla_f64_m(pg_1, contribs_1, xvv_1, mtxValues_1);
     2560             
     2561             				svbool_t pg_2 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_2);
     2562             				svfloat64_t mtxValues_2 = svld1_f64(pg_2, &currentValues_2[j]);
     2563             				svuint64_t indices_2 = svld1sw_u64(pg_2, &currentColIndices_2[j]);
     2564             				svfloat64_t xvv_2 = svld1_gather_u64index_f64(pg_2, xv, indices_2);
     2565             
     2566             				contribs_2 = svmla_f64_m(pg_2, contribs_2, xvv_2, mtxValues_2);
     2567             
     2568             				svbool_t pg_3 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_3);
     2569             				svfloat64_t mtxValues_3 = svld1_f64(pg_3, &currentValues_3[j]);
     2570             				svuint64_t indices_3 = svld1sw_u64(pg_3, &currentColIndices_3[j]);
     2571             				svfloat64_t xvv_3 = svld1_gather_u64index_f64(pg_3, xv, indices_3);
     2572             
     2573             				contribs_3 = svmla_f64_m(pg_3, contribs_3, xvv_3, mtxValues_3);
     2574             
     2575             				svbool_t pg_4 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_4);
     2576             				svfloat64_t mtxValues_4 = svld1_f64(pg_4, &currentValues_4[j]);
     2577             				svuint64_t indices_4 = svld1sw_u64(pg_4, &currentColIndices_4[j]);
     2578             				svfloat64_t xvv_4 = svld1_gather_u64index_f64(pg_4, xv, indices_4);
     2579             
     2580             				contribs_4 = svmla_f64_m(pg_4, contribs_4, xvv_4, mtxValues_4);
     2581             
     2582             				svbool_t pg_5 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_5);
     2583             				svfloat64_t mtxValues_5 = svld1_f64(pg_5, &currentValues_5[j]);
     2584             				svuint64_t indices_5 = svld1sw_u64(pg_5, &currentColIndices_5[j]);
     2585             				svfloat64_t xvv_5 = svld1_gather_u64index_f64(pg_5, xv, indices_5);
     2586             
     2587             				contribs_5 = svmla_f64_m(pg_5, contribs_5, xvv_5, mtxValues_5);
     2588             
     2589             				svbool_t pg_6 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_6);
     2590             				svfloat64_t mtxValues_6 = svld1_f64(pg_6, &currentValues_6[j]);
     2591             				svuint64_t indices_6 = svld1sw_u64(pg_6, &currentColIndices_6[j]);
     2592             				svfloat64_t xvv_6 = svld1_gather_u64index_f64(pg_6, xv, indices_6);
     2593             
     2594             				contribs_6 = svmla_f64_m(pg_6, contribs_6, xvv_6, mtxValues_6);
     2595             			}
     2596             
     2597             			double totalContribution_1 = svaddv_f64(svptrue_b64(), contribs_1);
     2598             			double sum_1 = rv[row_1] - totalContribution_1;
     2599             
     2600             			sum_1 += xv[row_1] * currentDiagonal_1;
     2601             			xv[row_1] = sum_1 / currentDiagonal_1;
     2602             
     2603             			double totalContribution_2 = svaddv_f64(svptrue_b64(), contribs_2);
     2604             			double sum_2 = rv[row_2] - totalContribution_2;
     2605             
     2606             			sum_2 += xv[row_2] * currentDiagonal_2;
     2607             			xv[row_2] = sum_2 / currentDiagonal_2;
     2608             
     2609             			double totalContribution_3 = svaddv_f64(svptrue_b64(), contribs_3);
     2610             			double sum_3 = rv[row_3] - totalContribution_3;
     2611             
     2612             			sum_3 += xv[row_3] * currentDiagonal_3;
     2613             			xv[row_3] = sum_3 / currentDiagonal_3;
     2614             
     2615             			double totalContribution_4 = svaddv_f64(svptrue_b64(), contribs_4);
     2616             			double sum_4 = rv[row_4] - totalContribution_4;
     2617             
     2618             			sum_4 += xv[row_4] * currentDiagonal_4;
     2619             			xv[row_4] = sum_4 / currentDiagonal_4;
     2620             
     2621             			double totalContribution_5 = svaddv_f64(svptrue_b64(), contribs_5);
     2622             			double sum_5 = rv[row_5] - totalContribution_5;
     2623             
     2624             			sum_5 += xv[row_5] * currentDiagonal_5;
     2625             			xv[row_5] = sum_5 / currentDiagonal_5;
     2626             
     2627             			double totalContribution_6 = svaddv_f64(svptrue_b64(), contribs_6);
     2628             			double sum_6 = rv[row_6] - totalContribution_6;
     2629             
     2630             			sum_6 += xv[row_6] * currentDiagonal_6;
     2631             			xv[row_6] = sum_6 / currentDiagonal_6;
     2632             		}
     2633             
     2634             //#pragma omp single
     2635             		if (maxLevelSize < tdgLevelSize) {
     2636             #ifndef HPCG_NO_OPENMP
     2637             #pragma omp for SCH_SYMGS(runtime)
     2638             #endif
     2639             		for ( local_int_t i = maxLevelSize; i < tdgLevelSize; i++ ) {
     2640             
     2641             			local_int_t row = A.tdg[l][i];
     2642             			const double * const currentValues = A.matrixValues[row];
     2643             			const local_int_t * const currentColIndices = A.mtxIndL[row];
     2644             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     2645             			const double currentDiagonal = matrixDiagonal[row][0];
     2646             			svfloat64_t contribs = svdup_f64(0.0);
     2647             
     2648             			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
     2649             				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
     2650             				
     2651             				svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
     2652             				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
     2653             				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
     2654             
     2655             				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
     2656             			}
     2657             
     2658             			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
     2659             			double sum = rv[row] - totalContribution;
     2660             
     2661             			sum += xv[row] * currentDiagonal;
     2662             			xv[row] = sum / currentDiagonal;
     2663             		}
     2664             		}
     2665             #ifndef HPCG_NO_OPENMP
     2666             	}
     2667             #endif
     2668             	}
     2669             
     2670             	/*
     2671             	 * BACKWARD SWEEP
     2672             	 */
     2673             	for ( local_int_t l = A.tdg.size()-1; l >= 0; l-- ) {
     2674             		local_int_t tdgLevelSize = A.tdg[l].size();
     2675             		local_int_t maxLevelSize = 6*(tdgLevelSize / 6);
     2676             
     2677             #ifndef HPCG_NO_OPENMP
     2678             #pragma omp parallel 
     2679             	{
     2680             		//#pragma omp single nowait 
     2681             		//{
     2682             		#pragma omp for nowait SCH_SYMGS(runtime)
     2683             #endif
     2684             		for ( local_int_t i = tdgLevelSize-1; i >= maxLevelSize; i-- ) {
     2685             
     2686             			local_int_t row = A.tdg[l][i];
     2687             			const double * const currentValues = A.matrixValues[row];
     2688             			const local_int_t * const currentColIndices = A.mtxIndL[row];
     2689             			const int currentNumberOfNonzeros = A.nonzerosInRow[row];
     2690             			const double currentDiagonal = matrixDiagonal[row][0];
     2691             			svfloat64_t contribs = svdup_f64(0.0);
     2692             
     2693             			for ( local_int_t j = 0; j < currentNumberOfNonzeros; j += svcntd()) {
     2694             				svbool_t pg = svwhilelt_b64_u64(j, currentNumberOfNonzeros);
     2695             				
     2696             				svfloat64_t mtxValues = svld1_f64(pg, &currentValues[j]);
     2697             				svuint64_t indices = svld1sw_u64(pg, &currentColIndices[j]);
     2698             				svfloat64_t xvv = svld1_gather_u64index_f64(pg, xv, indices);
     2699             
     2700             				contribs = svmla_f64_m(pg, contribs, xvv, mtxValues);
     2701             			}
     2702             
     2703             			double totalContribution = svaddv_f64(svptrue_b64(), contribs);
     2704             			double sum = rv[row] - totalContribution;
     2705             
     2706             			sum += xv[row] * currentDiagonal;
     2707             			xv[row] = sum / currentDiagonal;
     2708             		}
     2709             #ifndef HPCG_NO_OPENMP
     2710             		//}
     2711             #pragma omp for SCH_SYMGS(runtime)
     2712             #endif
     2713             		for ( local_int_t i = maxLevelSize-1; i >= 0; i-= 6 ) {
     2714             			local_int_t row_1 = A.tdg[l][i];
     2715             			local_int_t row_2 = A.tdg[l][i-1];
     2716             			local_int_t row_3 = A.tdg[l][i-2];
     2717             			local_int_t row_4 = A.tdg[l][i-3];
     2718             			local_int_t row_5 = A.tdg[l][i-4];
     2719             			local_int_t row_6 = A.tdg[l][i-5];
     2720             			const double * const currentValues_1 = A.matrixValues[row_1];
     2721             			const double * const currentValues_2 = A.matrixValues[row_2];
     2722             			const double * const currentValues_3 = A.matrixValues[row_3];
     2723             			const double * const currentValues_4 = A.matrixValues[row_4];
     2724             			const double * const currentValues_5 = A.matrixValues[row_5];
     2725             			const double * const currentValues_6 = A.matrixValues[row_6];
     2726             			const local_int_t * const currentColIndices_1 = A.mtxIndL[row_1];
     2727             			const local_int_t * const currentColIndices_2 = A.mtxIndL[row_2];
     2728             			const local_int_t * const currentColIndices_3 = A.mtxIndL[row_3];
     2729             			const local_int_t * const currentColIndices_4 = A.mtxIndL[row_4];
     2730             			const local_int_t * const currentColIndices_5 = A.mtxIndL[row_5];
     2731             			const local_int_t * const currentColIndices_6 = A.mtxIndL[row_6];
     2732             			const int currentNumberOfNonzeros_1 = A.nonzerosInRow[row_1];
     2733             			const int currentNumberOfNonzeros_2 = A.nonzerosInRow[row_2];
     2734             			const int currentNumberOfNonzeros_3 = A.nonzerosInRow[row_3];
     2735             			const int currentNumberOfNonzeros_4 = A.nonzerosInRow[row_4];
     2736             			const int currentNumberOfNonzeros_5 = A.nonzerosInRow[row_5];
     2737             			const int currentNumberOfNonzeros_6 = A.nonzerosInRow[row_6];
     2738             			const double currentDiagonal_1 = matrixDiagonal[row_1][0];
     2739             			const double currentDiagonal_2 = matrixDiagonal[row_2][0];
     2740             			const double currentDiagonal_3 = matrixDiagonal[row_3][0];
     2741             			const double currentDiagonal_4 = matrixDiagonal[row_4][0];
     2742             			const double currentDiagonal_5 = matrixDiagonal[row_5][0];
     2743             			const double currentDiagonal_6 = matrixDiagonal[row_6][0];
     2744             			svfloat64_t contribs_1 = svdup_f64(0.0);
     2745             			svfloat64_t contribs_2 = svdup_f64(0.0);
     2746             			svfloat64_t contribs_3 = svdup_f64(0.0);
     2747             			svfloat64_t contribs_4 = svdup_f64(0.0);
     2748             			svfloat64_t contribs_5 = svdup_f64(0.0);
     2749             			svfloat64_t contribs_6 = svdup_f64(0.0);
     2750             
     2751             			const int maxNumberOfNonzeros1 = std::max(currentNumberOfNonzeros_1, currentNumberOfNonzeros_2);				
     2752             			const int maxNumberOfNonzeros2 = std::max(currentNumberOfNonzeros_3, currentNumberOfNonzeros_4);				
     2753             			const int maxNumberOfNonzeros3 = std::max(currentNumberOfNonzeros_5, currentNumberOfNonzeros_6);				
     2754             			const int maxNumberOfNonzeros4 = std::max(maxNumberOfNonzeros1, maxNumberOfNonzeros2);				
     2755             			const int maxNumberOfNonzeros = std::max(maxNumberOfNonzeros3, maxNumberOfNonzeros4);				
     2756             							
     2757             			for ( local_int_t j = 0; j < maxNumberOfNonzeros; j += svcntd()) {
     2758             				svbool_t pg_1 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_1);
     2759             				svbool_t pg_2 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_2);
     2760             				svbool_t pg_3 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_3);
     2761             				svbool_t pg_4 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_4);
     2762             				svbool_t pg_5 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_5);
     2763             				svbool_t pg_6 = svwhilelt_b64_u64(j, currentNumberOfNonzeros_6);
     2764             				
     2765             				svfloat64_t mtxValues_1 = svld1_f64(pg_1, &currentValues_1[j]);
     2766             				svfloat64_t mtxValues_2 = svld1_f64(pg_2, &currentValues_2[j]);
     2767             				svfloat64_t mtxValues_3 = svld1_f64(pg_3, &currentValues_3[j]);
     2768             				svfloat64_t mtxValues_4 = svld1_f64(pg_4, &currentValues_4[j]);
     2769             				svfloat64_t mtxValues_5 = svld1_f64(pg_5, &currentValues_5[j]);
     2770             				svfloat64_t mtxValues_6 = svld1_f64(pg_6, &currentValues_6[j]);
     2771             				svuint64_t indices_1 = svld1sw_u64(pg_1, &currentColIndices_1[j]);
     2772             				svuint64_t indices_2 = svld1sw_u64(pg_2, &currentColIndices_2[j]);
     2773             				svuint64_t indices_3 = svld1sw_u64(pg_3, &currentColIndices_3[j]);
     2774             				svuint64_t indices_4 = svld1sw_u64(pg_4, &currentColIndices_4[j]);
     2775             				svuint64_t indices_5 = svld1sw_u64(pg_5, &currentColIndices_5[j]);
     2776             				svuint64_t indices_6 = svld1sw_u64(pg_6, &currentColIndices_6[j]);
     2777             				svfloat64_t xvv_1 = svld1_gather_u64index_f64(pg_1, xv, indices_1);
     2778             				svfloat64_t xvv_2 = svld1_gather_u64index_f64(pg_2, xv, indices_2);
     2779             				svfloat64_t xvv_3 = svld1_gather_u64index_f64(pg_3, xv, indices_3);
     2780             				svfloat64_t xvv_4 = svld1_gather_u64index_f64(pg_4, xv, indices_4);
     2781             				svfloat64_t xvv_5 = svld1_gather_u64index_f64(pg_5, xv, indices_5);
     2782             				svfloat64_t xvv_6 = svld1_gather_u64index_f64(pg_6, xv, indices_6);
     2783             
     2784             				contribs_1 = svmla_f64_m(pg_1, contribs_1, xvv_1, mtxValues_1);
     2785             				contribs_2 = svmla_f64_m(pg_2, contribs_2, xvv_2, mtxValues_2);
     2786             				contribs_3 = svmla_f64_m(pg_3, contribs_3, xvv_3, mtxValues_3);
     2787             				contribs_4 = svmla_f64_m(pg_4, contribs_4, xvv_4, mtxValues_4);
     2788             				contribs_5 = svmla_f64_m(pg_5, contribs_5, xvv_5, mtxValues_5);
     2789             				contribs_6 = svmla_f64_m(pg_6, contribs_6, xvv_6, mtxValues_6);
     2790             			}
     2791             
     2792             			double totalContribution_1 = svaddv_f64(svptrue_b64(), contribs_1);
     2793             			double totalContribution_2 = svaddv_f64(svptrue_b64(), contribs_2);
     2794             			double totalContribution_3 = svaddv_f64(svptrue_b64(), contribs_3);
     2795             			double totalContribution_4 = svaddv_f64(svptrue_b64(), contribs_4);
     2796             			double totalContribution_5 = svaddv_f64(svptrue_b64(), contribs_5);
     2797             			double totalContribution_6 = svaddv_f64(svptrue_b64(), contribs_6);
     2798             			double sum_1 = rv[row_1] - totalContribution_1;
     2799             			double sum_2 = rv[row_2] - totalContribution_2;
     2800             			double sum_3 = rv[row_3] - totalContribution_3;
     2801             			double sum_4 = rv[row_4] - totalContribution_4;
     2802             			double sum_5 = rv[row_5] - totalContribution_5;
     2803             			double sum_6 = rv[row_6] - totalContribution_6;
     2804             
     2805             			sum_1 += xv[row_1] * currentDiagonal_1;
     2806             			sum_2 += xv[row_2] * currentDiagonal_2;
     2807             			sum_3 += xv[row_3] * currentDiagonal_3;
     2808             			sum_4 += xv[row_4] * currentDiagonal_4;
     2809             			sum_5 += xv[row_5] * currentDiagonal_5;
     2810             			sum_6 += xv[row_6] * currentDiagonal_6;
     2811             			xv[row_1] = sum_1 / currentDiagonal_1;
     2812             			xv[row_2] = sum_2 / currentDiagonal_2;
     2813             			xv[row_3] = sum_3 / currentDiagonal_3;
     2814             			xv[row_4] = sum_4 / currentDiagonal_4;
     2815             			xv[row_5] = sum_5 / currentDiagonal_5;
     2816             			xv[row_6] = sum_6 / currentDiagonal_6;
     2817             		}
     2818             #ifndef HPCG_NO_OPENMP
     2819             	}
     2820             #endif
     2821             	}
     2822             }
Total prefetch num: 0
Optimization messages
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 20: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 21: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 21: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 28: Inline expansion is applied to the user defined function '_ZNSt3__13maxIiEERKT_S3_S3_'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 34: Inline expansion is applied to the user defined function '_ZNSt3__13minIiEERKT_S3_S3_'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 48: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 48: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 49: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 49: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 50: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 50: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 51: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 51: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 76: Inline expansion is applied to the user defined function '_ZNSt3__13maxIiEERKT_S3_S3_'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 77: Inline expansion is applied to the user defined function '_ZNSt3__13maxIiEERKT_S3_S3_'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 78: Inline expansion is applied to the user defined function '_ZNSt3__13maxIiEERKT_S3_S3_'.
  jwd6142s-i  "../src/ComputeSYMGS_OPT.cpp", line 80: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS_OPT.cpp", line 80: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 144: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 144: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6142s-i  "../src/ComputeSYMGS_OPT.cpp", line 151: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS_OPT.cpp", line 151: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 172: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 172: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6142s-i  "../src/ComputeSYMGS_OPT.cpp", line 179: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS_OPT.cpp", line 179: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 201: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 201: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6142s-i  "../src/ComputeSYMGS_OPT.cpp", line 208: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS_OPT.cpp", line 208: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 231: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 233: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 243: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 247: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 247: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 248: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS_OPT.cpp", line 248: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6142s-i  "../src/ComputeSYMGS_OPT.cpp", line 255: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 322: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 326: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 326: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 327: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 327: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6142s-i  "../src/ComputeSYMGS.cpp", line 334: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS.cpp", line 334: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 349: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 349: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 350: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 355: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 359: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 359: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 360: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 360: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6142s-i  "../src/ComputeSYMGS.cpp", line 367: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS.cpp", line 367: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 409: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 418: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 419: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 432: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6142s-i  "../src/ComputeSYMGS.cpp", line 455: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS.cpp", line 455: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd6142s-i  "../src/ComputeSYMGS.cpp", line 511: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS.cpp", line 511: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd6142s-i  "../src/ComputeSYMGS.cpp", line 547: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS.cpp", line 547: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 572: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 578: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 579: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 593: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6142s-i  "../src/ComputeSYMGS.cpp", line 616: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS.cpp", line 616: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd6142s-i  "../src/ComputeSYMGS.cpp", line 672: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS.cpp", line 672: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd6142s-i  "../src/ComputeSYMGS.cpp", line 708: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS.cpp", line 708: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1404: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1408: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1408: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1409: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1409: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6004s-i  "../src/ComputeSYMGS.cpp", line 1416: SIMD conversion is applied to this loop with the loop variable 'j'. The loop contains a reduction operation.
  jwd8204o-i  "../src/ComputeSYMGS.cpp", line 1416: This loop is software pipelined.
  jwd8205o-i  "../src/ComputeSYMGS.cpp", line 1416: The software-pipelined loop is chosen at run time when the iteration count is greater than or equal to 192.
  jwd8208o-i  "../src/ComputeSYMGS.cpp", line 1418: Method of calculating sum or product is changed.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1422: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1422: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1423: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1428: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1432: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1432: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1433: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1433: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6004s-i  "../src/ComputeSYMGS.cpp", line 1440: SIMD conversion is applied to this loop with the loop variable 'j'. The loop contains a reduction operation.
  jwd8204o-i  "../src/ComputeSYMGS.cpp", line 1440: This loop is software pipelined.
  jwd8205o-i  "../src/ComputeSYMGS.cpp", line 1440: The software-pipelined loop is chosen at run time when the iteration count is greater than or equal to 192.
  jwd8208o-i  "../src/ComputeSYMGS.cpp", line 1442: Method of calculating sum or product is changed.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1477: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1482: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1482: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1483: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1483: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6004s-i  "../src/ComputeSYMGS.cpp", line 1490: SIMD conversion is applied to this loop with the loop variable 'j'. The loop contains a reduction operation.
  jwd8204o-i  "../src/ComputeSYMGS.cpp", line 1490: This loop is software pipelined.
  jwd8205o-i  "../src/ComputeSYMGS.cpp", line 1490: The software-pipelined loop is chosen at run time when the iteration count is greater than or equal to 192.
  jwd8208o-i  "../src/ComputeSYMGS.cpp", line 1492: Method of calculating sum or product is changed.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1496: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1496: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1497: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1502: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1507: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1507: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEE4sizeEv'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1508: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorINS0_IiNS_9allocatorIiEEEENS1_IS3_EEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1508: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6004s-i  "../src/ComputeSYMGS.cpp", line 1515: SIMD conversion is applied to this loop with the loop variable 'j'. The loop contains a reduction operation.
  jwd8204o-i  "../src/ComputeSYMGS.cpp", line 1515: This loop is software pipelined.
  jwd8205o-i  "../src/ComputeSYMGS.cpp", line 1515: The software-pipelined loop is chosen at run time when the iteration count is greater than or equal to 192.
  jwd8208o-i  "../src/ComputeSYMGS.cpp", line 1517: Method of calculating sum or product is changed.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1547: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1553: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1554: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1576: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6142s-i  "../src/ComputeSYMGS.cpp", line 1576: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS.cpp", line 1576: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1581: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1594: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6142s-i  "../src/ComputeSYMGS.cpp", line 1594: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS.cpp", line 1594: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1597: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1605: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6142s-i  "../src/ComputeSYMGS.cpp", line 1605: SIMD conversion is not applied to this loop because the iteration count is uncertainty.
  jwd8671o-i  "../src/ComputeSYMGS.cpp", line 1605: This loop cannot be software pipelined because the shape of the loop is not covered by software pipelining.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1607: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1616: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1622: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1623: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1645: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6004s-i  "../src/ComputeSYMGS.cpp", line 1645: SIMD conversion is applied to this loop with the loop variable 'j'. The loop contains a reduction operation.
  jwd8204o-i  "../src/ComputeSYMGS.cpp", line 1645: This loop is software pipelined.
  jwd8205o-i  "../src/ComputeSYMGS.cpp", line 1645: The software-pipelined loop is chosen at run time when the iteration count is greater than or equal to 32.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1666: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6004s-i  "../src/ComputeSYMGS.cpp", line 1666: SIMD conversion is applied to this loop with the loop variable 'j'. The loop contains a reduction operation.
  jwd8204o-i  "../src/ComputeSYMGS.cpp", line 1666: This loop is software pipelined.
  jwd8205o-i  "../src/ComputeSYMGS.cpp", line 1666: The software-pipelined loop is chosen at run time when the iteration count is greater than or equal to 96.
  jwd8208o-i  "../src/ComputeSYMGS.cpp", line 1667: Method of calculating sum or product is changed.
  jwd8208o-i  "../src/ComputeSYMGS.cpp", line 1668: Method of calculating sum or product is changed.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1679: Inline expansion is applied to the user defined function '_ZNKSt3__16vectorIiNS_9allocatorIiEEEixEm'.
  jwd6004s-i  "../src/ComputeSYMGS.cpp", line 1679: SIMD conversion is applied to this loop with the loop variable 'j'. The loop contains a reduction operation.
  jwd8204o-i  "../src/ComputeSYMGS.cpp", line 1679: This loop is software pipelined.
  jwd8205o-i  "../src/ComputeSYMGS.cpp", line 1679: The software-pipelined loop is chosen at run time when the iteration count is greater than or equal to 192.
  jwd8208o-i  "../src/ComputeSYMGS.cpp", line 1680: Method of calculating sum or product is changed.
  jwd8101o-i  "../src/ComputeSYMGS.cpp", line 1729: Inline expansion is applied to the user defined function '_Z20ComputeSYMGS_TDG_SVERK19SparseMatrix_STRUCTRK13Vector_STRUCTRS2_R9TraceData'.
  jwd8101o-i  "/opt/FJSVstclanga/cp-1.0.21.01/bin/../include/libc++/v371/algorithm", line 2594: Inline expansion is applied to the user defined function '_ZNKSt3__16__lessIiiEclERKiS3_'.
  jwd8101o-i  "/opt/FJSVstclanga/cp-1.0.21.01/bin/../include/libc++/v371/algorithm", line 2602: Inline expansion is applied to the user defined function '_ZNSt3__13minIiNS_6__lessIiiEEEERKT_S5_S5_T0_'.
  jwd8101o-i  "/opt/FJSVstclanga/cp-1.0.21.01/bin/../include/libc++/v371/algorithm", line 2659: Inline expansion is applied to the user defined function '_ZNKSt3__16__lessIiiEclERKiS3_'.
  jwd8101o-i  "/opt/FJSVstclanga/cp-1.0.21.01/bin/../include/libc++/v371/algorithm", line 2667: Inline expansion is applied to the user defined function '_ZNSt3__13maxIiNS_6__lessIiiEEEERKT_S5_S5_T0_'.
Statistics information
  Option information
    Command line options : -c -DHPCG_CONTIGUOUS_ARRAYS -DHPCG_NO_MPI -DENABLE_MG_COUNTERS -DHPCG_USE_SVE -DHPCG_MAN_OPT_DDOT -DDDOT_2_UNROLL -DWAXPBY_AUTO_OPT -HPCG_MAN_OPT_SCHEDULE_ON -DHPCG_MAN_OPT_SPMV_UNROLL -DSPMV_4_UNROLL -Khpctag -Kzfill -DUNROLLING_4_B -I./src -I./src/OOKAMI_OMP_FJ -Kfast -KSVE -Kopenmp -ffast-math -funroll-loops -std=c++11 -ffp-contract=fast -march=armv8.2-a+sve -Kocl -Koptmsg=2 -Nlst=t -I../src -o src/ComputeSYMGS.o
    Effective options    : -g0 -mt -Qy -std=gnu++11 -x- -x=quick -O3 -Knoalias_const
                           -Kalign_loops -Knoarray_declaration_opt -Kassume=noshortloop
                           -Kassume=nomemory_bandwidth -Kassume=notime_saving_compilation
                           -Kcmodel=small -Keval -Keval_noconcurrent
                           -Knoextract_stride_store -Kfast_matmul -Knofenv_access
                           -Kfp_contract -Kfp_relaxed -Kfsimple -Kfz -Khpctag
                           -Kilfunc=procedure -Klargepage -Klib -Kloop_blocking
                           -Kloop_fission -Kloop_nofission_stripmining
                           -Kloop_fission_threshold=50 -Kloop_fusion -Kloop_interchange
                           -Kloop_part_simd -Kloop_perfect_nest -Kloop_noversioning
                           -Klooptype=f -Knomemalias -Kmfunc=1 -Kocl -Komitfp -Kopenmp
                           -Kopenmp_noassume_norecurrence
                           -Kopenmp_nocollapse_except_innermost
                           -Kopenmp_loop_variable=private -Kopenmp_noordered_reduction
                           -Knoopenmp_simd -Knooptlib_string -Koptmsg=2
                           -Knopc_relative_literal_loads -Knoparallel
                           -Kparallel_nofp_precision -Knopreex -Kprefetch_cache_level=all
                           -Kprefetch_noconditional -Kprefetch_noindirect -Kprefetch_noinfer
                           -Kprefetch_sequential=auto -Kprefetch_nostride -Kprefetch_strong
                           -Kprefetch_strong_L2 -Knopreload -Krdconv=1
                           -Kremove_inlinefunction -Knorestp -Ksch_post_ra -Ksch_pre_ra
                           -Ksibling_calls -Ksimd=auto -Ksimd_packed_promotion
                           -Ksimd_reduction_product -Ksimd_reg_size=512
                           -Ksimd_nouncounted_loop -Ksimd_use_multiple_structures
                           -Knostrict_aliasing -Knostriping -KA64FX -KARMV8_2_A -KSVE -Kswp
                           -Kswp_freg_rate=100 -Kswp_ireg_rate=100 -Kswp_preg_rate=100
                           -Kswp_policy=auto -Kunroll -Knounroll_and_jam -Kzfill
                           -Ncancel_overtime_compilation -Nnocoverage -Nexceptions -Nnofjcex
                           -Nfjprof -Nnohook_func -Nnohook_time -Nlibomp -Nline -Nlst=p
                           -Nlst=t -Nquickdbg=noheapchk -Nquickdbg=nosubchk -NRnotrap
                           -Nnoreordered_variable_stack -Nrt_notune -Nsetvalue=noheap
                           -Nsetvalue=nostack -Nsetvalue=noscalar -Nsetvalue=noarray
                           -Nsetvalue=nostruct -Nsrc -Nsta
